{"entries":[{"title":"Components catalog","baseurl":"","url":"/documentation/getting_started/adding_components.html","date":null,"categories":[],"body":"In Alien 4 Cloud you can design your applications by adding multiple components to a topology and defining relationships between them. The definition of components and topologies is based on TOSCA standard. Alien 4 Cloud allow you to add components into an indexed catalog that users can browser, search and filter to find the components they need. Adding components require ADMIN or COMPONENTS_MANAGER roles. TOSCA Normative types TOSCA standard defines some normative types that are the one you should leverage to get started. You can read more about TOSCA and the normative types in the TOSCA section of the documentation. In order to add Normative types in Alien 4 Cloud you must download the content of the tosca normative types repository as a Zip and drag and drop it in the Components view of Alien 4 Cloud. Alien 4 Cloud leverage TOSCA Simple Profile in YAML with a few changes allowing to support versioning of the components as well as imports based on the components catalog. We will soon allow however to export your components and topologies as pure TOSCA archives. "},{"title":"Administration","baseurl":"","url":"/documentation/admin/admin.html","date":null,"categories":[],"body":""},{"title":"Advanced configuration","baseurl":"","url":"/documentation/admin/advanced_configuration.html","date":null,"categories":[],"body":" Alien 4 Cloud contains a basic configuration that is good enough for test environment. However in order to move into production or in order to integrate with other systems (as LDAP for example), you need to define an advanced configuration. In order to provide configuration to Alien 4 Cloud, you must place an Alien configuration file along-side to the Alien 4 Cloud war. ├── alien4cloud-ui- { version } -standalone.war ├── alien4cloud-config.yml ├── elasticsearch.yml You can find default configurations for both files in the GitHub repository: alien4cloud-config.yml elasticsearch.yml Elastic Search configuration ALIEN 4 Cloud uses ElasticSearch as it’s data store and indexing service. By default ALIEN 4 Cloud starts up an embedded ElasticSearch node. Of course when running in production it is recommended to use a remote cluster (ideally with high availability configured). Common configuration Common configuration allows you to configure the name of the elasticsearch cluster ( clusterName ), as well as the prefix_max_expansions (performance setting used for prefix queries). We recommend that you don’t change the default prefix_max_expansions value. If you wish to change one of the parameters, you should open the alien4cloud-config.yml file and go to the elasticSearch configuration section. elasticSearch : clusterName : escluster local : false client : false resetData : false prefix_max_expansions : 10 local and resetData should be left to false. Configure the embedded Elastic Search The embedded Elastic Search configuration elasticsearch.yml is a native elastic search configuration and you can find plenty of information on elastic search website on how you can configure it. However the main element you may wish to configure is elastic search storage directories: path : data : ${user.home}/.calm/elasticsearch/data work : ${user.home}/.calm/elasticsearch/work logs : ${user.home}/.calm/elasticsearch/logs Configure a remote Elastic Search In order to configure a remote Elastic Search, you should edit the following: In alien4cloud-config.yml file, edit the elasticSearch section and change client from false to true: elasticSearch : clusterName : escluster local : false client : true resetData : false prefix_max_expansions : 10 In the elasticsearch.yml make sure that the connection parameters matches the ones of your elasticsearch cluster. Example: discovery.zen.ping.multicast.enabled : false discovery.zen.ping.unicast.enabled : true discovery.zen.ping.unicast.hosts : localhost Directories configuration ALIEN 4 Cloud store various files on the hard drive. Cloud Service archives, Artifacts overriden in the topologies, plugins archives etc. Directories can be configured in the alien4cloud-config.yml file. By default, ALIEN 4 Cloud stores data in the user home directory in a .calm folder. # Configuration of Calm's CSAR repository, temporary folder and upload settings. directories : # Alien 4 cloud main directory (other directories are relative path to this one) calm : ${user.home}/.calm # directory in which alien 4 cloud stores Cloud Service Archives csar_repository : csar # directory in which alien 4 cloud stores uploaded artifacts (war etc.). artifact_repository : artifacts # temporary directory for alien 4 cloud upload_temp : upload # directory in which alien 4 cloud unzips loaded plugins. plugins : plugins Admin user initialization In case there is no admin user in it’s repository, ALIEN 4 Cloud can automatically create a user with ADMIN rights. The user name and password are configured in the alien4cloud-config.yml file. Of course if an ADMIN user already exists in ALIEN then no user is created and this section is ignored. # Configuration of default admin ensurer, if true it creates a default admin user if no admin can be found in the system. users : admin : # Alien 4 cloud checks that an admin user is defined at the application launch. ensure : true username : admin password : admin email : admin@mycompany.com LDAP configuration See specific sub-section . Component search boost ALIEN 4 Cloud is managing a custom way to rank components when searching for them. In order to compute the boost for a component we get the number of topologies that uses the component and multiply it by the usage factor. Then, if a component is the latest version we add a fixed version boost, finally if a component is marked as default for at least one of it’s capability, we add another default fixed boost. In order to change the default weights you can edit the following configuration: # configure the boost factors for tosca elements in the search, elements with the highest boost factor appears first in search results # the total boost factor for a component is the sum of the following boost factors. components.search.boost : # boost components that are used in topologies by (number of active topologies that uses the component * usage) usage : 1 # components that exist in latest version get a boost factor regarding other components. Note that this factor should be very high as every component # with latest version will be boosted. version : 1000 # components that are configured as default for at least 1 capability get the following a boost factor. default : 10 "},{"title":"Application(s) configuration","baseurl":"","url":"/documentation/getting_started/application_configuration.html","date":null,"categories":[],"body":"Introduction to the application concepts In Alien 4 Cloud we manage all applications by a version and environment system. A version represents a given state for a topology. An environment is the combination of a version and a cloud with a specific type who represent the goal of your environment. For example, we can have the “Wordpress” application in version “1.0-SNAPSHOT”. To deploy it, we create an new environment with this version, type “Development” and a cloud like OpenStack. Manage your applications version When you create an application, Alien 4 Cloud creates a default version “0.1.0-SNAPSHOT”. The qualifier SNAPSHOT is really important because we can only modify the topology version with this qualifier. The description is used to describe a goal of our version. When you create a new version you can specify another version of your application as template to duplicate it’s topology. To learn how to create a topology, read the LAMP Stack Application Topology Manage your applications environment Like for application version, a default application environment named “Environment” is created when you create your application. This new environment is configured to target the default created version but without any associated cloud. You can specify the cloud in the environment management page or in the deployment page. You can also add a type to your environment and write a description. Application environment is a good way to design your application lifecycle accross the different environments and, eventually, clouds. For example you can design one or more development environments for your developers (on EC2 for example), and the pre-production and production environments on your own OpenStack(s). You can then move a version from an environment to another by switching the version on the environments and re-deploying it. In future version we plan to allow version upgrades without having to restart an environment. In the application environment management page you can also see all statuses of all environments for an application. Moreover, the “info” view will also display those informations. In summary, the combination of version and environment concepts offers the ability of manage the lifecycle of your application. Deploy an application and runtime view When you have a cloud and an application with a complete environment, you can deploy your application. Note that your version’s topology must also be “valid”. The deployment page checks the presence of components in your topology or the presence of all required properties. When all requirements are satisfied, you can chose a cloud image and launch the deployment. That will enable the runtime view who display all events of the targeted cloud. While your topology is deployed, you can have more details about each instance of all nodes (IP addresses etc.) on the runtime view. "},{"title":"Artifact definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/artifact_definition.html","date":null,"categories":[],"body":"An artifact definition defines a named, typed file that can be associated with Node Type or Node Template and used by orchestration engine to facilitate deployment and implementation of interface operations. Keynames Keyname Type Required Description type no string The optional data type for the artifact definition. description no string The optional description for the artifact definition. mime_type no string The optional Mime type for finding the correct artifact definition when it is not clear from the file extension. deploy_path no string The file path the associated file would be deployed into within the target node’s container. Current implementation of Alien 4 Cloud does not take the deploy_path in account but rather keeps the archive layout for scripts copy. Grammar # Simple form - type and mime inferred from file URI <artifact_name> : <artifact_file_URI> # Qualified form - type and mime explicit <artifact_name> : <artifact_file_URI> type : <artifact_type_name> description : <artifact_description> mime_type : <artifact_mime_type_name> Example The following example shows how to define a node type with operation: node_types : fastconnect.nodes.OperationSample : artifacts : - scripts_directory : scrips type : tosca.artifacts.File description : Directory that contains all scripts. "},{"title":"Artifact type","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/artifact_type.html","date":null,"categories":[],"body":"An Artifact Type is a reusable entity that defines the type of one or more files which Node Types or Node Templates can have dependent relationships and used during operations such as during installation or deployment. Keynames Keyname Type Required Description derived_from string no An optional parent Artifact Type name the Artifact Type derives from. description string no An optional description for the Artifact Type. mime_type string yes The required mime type property for the Artifact Type. file_ext string[] yes The required file extension property for the Artifact Type. properties property definitions no An optional list of property definitions for the Artifact Type. Grammar <artifact_type_name> : derived_from : <parent_artifact_type_name> description : <artifact_description> mime_type : <mime_type_string> file_ext : [ <file_extension_1> , ... , <file_extension_n> ] properties : <property_definitions> See: property_definitions Example The following example shows how to define a node type with operation: my_artifact_type : description : Java Archive artifact type derived_from : tosca.artifact.Root mime_type : application/java-archive file_ext : [ jar ] "},{"title":"Attribute definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/attribute_definition.html","date":null,"categories":[],"body":"An attribute definition defines a named, typed value that can be associated with an entity defined in this specification (e.g., a Node Type or Relationship Type). Specifically, it is used to expose a value that is set by the orchestrator after the entity has been instantiated (as part of an instance model). Typically, this value can be retrieved via a function from the instance model and used as inputs to other entities or implementation artifacts. Keynames Keyname Type Required Description type string yes The required data type for the attribute. description string no The optional description for the attribute. default N/A no An optional key that may provide a value to be used as a default if not provided by another means. This value SHALL be type compatible with the type declared by the attribute definition’s type keyname. Grammar <attribute_name> : type : <attribute_type> description : <attribute_description> default : <attribute_default_value> Example The following example shows how to define a node type with attributes: node_types : fastconnect.nodes.AttributeSample : attributes : property_1 : type : string property_2 : type : string description : this is the second attribute of the node default : This is the default value of the attribute property_3 : type : integer default : 45 "},{"title":"Backup and restore","baseurl":"","url":"/documentation/admin/backup_restore.html","date":null,"categories":[],"body":"Alien 4 Cloud uses several places to store it’s data. Cloud service archives Artifacts that may have been uploaded to build topologies Indexed data (stored in elastic-search) Plugins binaries Eventually you should make sure to backup also your alien4cloud yaml configuration file as well as your elastic search configuration file Backup In order to backup Alien 4 Cloud you must backup elastic search indexes as well as disk-based data. For more informations on how to backup an elasticsearch cluster please refer the elastic search documentation The following bash script gives an example on how alien4cloud data should be backed-up. It assumes that you kept the defaut directory hierarchy for alien data. # Directory in which alien stores it's disk base data. export ALIEN_DIR = ~/.alien # Url to access ElasticSearch rest api. export ES_URL = \"http://localhost:9200\" # Backup target directories export BACKUP_DIR = ~/tmp/alien_backups export BACKUP_NAME = ` date '+%d_%m_%Y_%H_%M' ` export ES_BACKUP_DIR = $BACKUP_DIR /elasticsearch export FS_BACKUP_DIR = $BACKUP_DIR /filesystem/ $BACKUP_NAME # setup elastic search snapshot repository curl -XPUT \"$ES_URL/_snapshot/alien_backup\" -d \"{ \\\"type\\\": \\\"fs\\\", \\\"settings\\\": { \\\"location\\\": \\\"$ES_BACKUP_DIR\\\", \\\"compress\\\": true } }\" # trigger elastic search data backup (asynchronous) RESULT = ` curl -XPUT \"$ES_URL/_snapshot/alien_backup/$BACKUP_NAME?wait_for_completion=false\" ` SUCCESS = $( echo \"$RESULT\" | grep \"{\\\"accepted\\\":true}\" ) if [ -z \"$SUCCESS\" ] ; then echo \"Failed to backup Elastic Search\" echo $RESULT else # Copy file system data mkdir -p $FS_BACKUP_DIR /artifacts mkdir -p $FS_BACKUP_DIR /csar mkdir -p $FS_BACKUP_DIR /plugins cp -r $ALIEN_DIR /artifacts $FS_BACKUP_DIR /artifacts cp -r $ALIEN_DIR /csar $FS_BACKUP_DIR /csar cp -r $ALIEN_DIR /plugins $FS_BACKUP_DIR /plugins # wait until elastic search backup is complete curl -XGET \"$ES_URL/_snapshot/alien_backup/$BACKUP_NAME/_status\" fi Restore We recommend users to stop alien 4 cloud but not ElasticSearch in order to perform the restore. Alien 4 Cloud should be restarted once restore is completed. However, if you 100% sure that restore operation has no impact on clouds or plugins configuration you can perform a ‘hot restore’ and don’t need to stop neither Alien 4 Cloud or ElasticSearch. In order to perform a restore with elasticsearch up and alien down you should be running in a classical production setup where elasticsearch process is independant from alien 4 cloud. See advanced configuration for more details. To restore a snapshot you should restore the elaticsearch index and put back the actual files required for Alien 4 Cloud. Before to run the script below you should make sure that alien 4 cloud is stopped and elastic-search is running. # Name of the backup to restore export BACKUP_NAME = $1 echo \"Prepare to restore $BACKUP_NAME\" # Directory in which alien stores it's disk base data. export ALIEN_DIR = ~/.alien # Url to access ElasticSearch rest api. export ES_URL = \"http://localhost:9200\" # Backup target directories export BACKUP_DIR = ~/tmp/alien_backups export FS_BACKUP_DIR = $BACKUP_DIR /filesystem/ $BACKUP_NAME # close indexes before restore operation curl -XPOST \"$ES_URL/_all/_close\" # trigger elastic search data restore RESULT = ` curl -XPOST \"$ES_URL/_snapshot/alien_backup/$BACKUP_NAME/_restore\" ` SUCCESS = $( echo \"$RESULT\" | grep \"{\\\"accepted\\\":true}\" ) if [ -z \"$SUCCESS\" ] ; then echo \"Failed to restore Elastic Search\" echo $RESULT else # Copy file system data rm -r $ALIEN_DIR /artifacts rm -r $ALIEN_DIR /csar rm -r $ALIEN_DIR /plugins cp -r $FS_BACKUP_DIR /artifacts $ALIEN_DIR /artifacts cp -r $FS_BACKUP_DIR /csar $ALIEN_DIR /csar cp -r $FS_BACKUP_DIR /plugins $ALIEN_DIR /plugins fi Once data is restored you can restart alien 4 cloud server. "},{"title":"Defaut Blockstorage","baseurl":"","url":"/documentation/cloudify2_driver/blockstorage.html","date":null,"categories":[],"body":"Here are informations about the default normative type Blockstorage support. tosca.nodes.BlockStorage type You should add the node type tosca.nodes.BlockStorage to your topology, and attach it to a compute node. Node properties volumeId The provider can attach to a compute a created and formatted storage. Thus, you need to provide it for the ID of the volume you would like to attach, through the node property volumeId . size If no volumeId is provided, the provider will check for the size property, and use it to match a storage compute configured in the used cloud. Then, it will create a new volume, and format it ( default file system is ext4 ). How it works provider configuration If you have storage templates defined in your Clouify cloud’s file, you can configure them in the provider. Flow First you should add a BlockStorage node to your topology, attach it to a Compute node, and fill in if necessary the properties volumeId and size . When the provider process the topology for deployment, If the volumeId is defined , the provider will: try to locate the storage attach it to the compute mount it to the /mountedStorage directory. Else, if the size is defined , it will: Try to determin a storage template matching the exact given size. Create a volume based on the choosen template Format it using ext4 file system attach it to the compute mount it to the /mountedStorage directory. When the volume is created, his Id is updated in the deployed topology , so that it could be reused fro the next deployment. If neither the volumeId nor the size are defined, the provider will use the storage template difined with the lowest size to create the volume. When undeploying the application, the provider will: unmount the strorage detach it from the compute node to set free the resource. Note that the data are not deleted . Working with scaling policy If you are deploying the application with more than one instance, you can provide comma separated volumes Ids, ordered by instances id. Let take an example for illustration: deploying with the following configuations: minInstances : 1 maxInstance : 3 initialInstances : 3 volumeId : a,b,c Then, the instance 1,2,3 will use respectively the Ids a,b,c . As for the instance 4 , if a size is specified, it will be used to find the matching storage template (if not the default template is used) and create a volume ( d ). After then, the volumeId property will be updated to a,b,c,d . As stated previously, a storage created with the type tosca.nodes.BlockStorage is not deleted when undeploying the concerned application. However, if you want a storage auto-deletable, you can use the type alien.nodes.DeletableBlockStorage . That will ensure that the volume is destroyed, but of course the topology won’t be updated with the created volumeId. "},{"title":"ALIEN Components repository","baseurl":"","url":"/documentation/tosca_ref/calm_components_repo.html","date":null,"categories":[],"body":"Alien 4 Cloud allow users to import their TOSCA Cloud Service Archive. Alien 4 Cloud manages an archive repository as well as an index of TOSCA types. Uploading your archives in ALIEN You cannot upload the same archive (same id and version) mutliple times. If you changed an archive, you must increment the version number so you can upload it to ALIEN . Browsing the service repository When a cloud service archive is uploaded, "},{"title":"Components archive","baseurl":"","url":"/documentation/tosca_ref/calm_components_repo_uploadarchive.html","date":null,"categories":[],"body":"How to upload your components archives in ALIEN You cannot upload the same archive (same id and version) mutliple times. If you changed an archive, you must increment the version number so you can upload it to ALIEN . Only users with role COMPONENT_MANAGER can upload archive file. There are two ways to upload components descriptions in ALIEN regarding you browser capabilities : Drag&Drop disabled Click on [Upload CSAR] > Select your archive (The file is automaticly uploaded) Drag&Drop enabled Drag you archile file > Drop it on the dash dotted area After upload After an archive file upload you should now have the following view : You can now browse and search for components . "},{"title":"Capability definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/capability_definition.html","date":null,"categories":[],"body":"A capability definition defines a named, typed set of data that can be associated with Node Type or Node Template to describe a transparent capability or feature of the software component the node describes. Keynames Keyname Type Required Description type string yes Type of capability or node that is required by the current node. description string no The optional description of the Capability Type. properties list of properties values no Properties values for the properties defined on the capability type. attributes list of attributes values no Attributes values for the attributes defined on the capability type. upper_bound integer (or unbounded string) no Specifies the upper boundary of client requirements the defined capability can serve. A value of unbounded indicates that there is no upper boundary. Defaults to unbounded. upper_bound is an Alien specific property that is currently not part of the official specification for the TOSCA simple profile in YAML. Grammar # Simple definition is as follows: <capability_defn_name> : <capability_type> # The full definition is as follows: <capability_defn_name> : type : <capability_type> description : <capability_defn_description> properties : <property_values> attributes : <attribute_values> upper_bound : <upper_bound> Example node_types : fastconnect.nodes.CapabilitySample : capabilities : # Simple form, no properties defined or augmented test_capability : mytypes.mycapabilities.MyCapabilityTypeName # Full form, augmenting properties of the referenced capability type some_capability : type : mytypes.mycapabilities.MyCapabilityTypeName properties : limit : 100 upper_bound : 3 "},{"title":"Capability type","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/capability_type.html","date":null,"categories":[],"body":"A Capability Type is a reusable entity that describes a kind of capability that a Node Type can declare to expose. Requirements (implicit or explicit) that are declared as part of one node can be matched to (i.e., fulfilled by) the Capabilities declared by other node. Keynames Keyname Type Required Description derived_from string no An optional parent Capability Type name the Capability Type derives from. description string no An optional description for the Capability Type. properties property definitions no An optional list of property definitions for the Capability Type. Grammar <capability_type_name> : derived_from : <parent_capability_type_name> description : <capability_description> properties : <property_definitions> See: property_definitions Example The following example shows how to define a node type with operation: mycompany.mytypes.myapplication.MyFeature : derived_from : tosca.capabilities.Feature description : a custom feature of my company’s application properties : my_feature_setting : type : string my_feature_value : type : integer "},{"title":"Cloud Service Archive","baseurl":"","url":"/documentation/tosca_ref/cloud_service_archive.html","date":null,"categories":[],"body":"Every elements in TOSCA must be contained into a Cloud Service Archive (CSAR). A Cloud Service Archive is a folder or a zip file that contains types and templates definitions and any other files required for elements implementations. ├── my-definition-file.yml ├── images │   ├── component-icon.png │   └── ... ├── scripts │   └── install.sh ├── lib │   └── tosca-normative-types.yml The entry point for the Cloud Service Archive are the definitions files that are placed at the root of the Archive. Basically this is any .yaml or .yml file that can be found at the Archive root. Alien 4 Cloud currently supports only a single service definitions file at the root level. This definition file can however reference other definitions files within the archive through the imports feature. "},{"title":"Customizing Cloudify","baseurl":"","url":"/documentation/cloudify2_driver/cloudify.html","date":null,"categories":[],"body":"Before everything, you need a running instance of Cloudify. The instance can be launched wherever you want, but make sure to have access to the REST API’s URL, which will be needed later on. Setup Make sure you have installed a Java JDK 1.6 or higher and set your JAVA_HOME properly. The recommended version is JDK 7u45 Download and unzip the Cloudify distribution file. Now for this driver to work, you have to customize your instaled Cloudify. Custom events In order to handle Cloudify lifecycle events, and to emit our own events, we need the alien4cloud-cloudify-custom-events . This provides a REST API and uses the Gigaspace management space to store the events. Download the zip archive and unzip it into the upload folder of your prefered cloud driver (e.g. gigaspaces-cloudify-2.7.0-ga/clouds/openstack-havana/upload ) In the same upload folder, edit the bootstrap-management.sh : Locate the ligne ./cloudify.sh $START_COMMAND $START_COMMAND_ARGS add right after that line, add the following snippet if [ \"$GSA_MODE\" = \"lus\" ] ; then chmod +x ${ WORKING_HOME_DIRECTORY } /events/bin/gsDeployEventsWar.sh ${ WORKING_HOME_DIRECTORY } /events/bin/gsDeployEventsWar.sh fi Bootstrap your cloud, and when done, note the REST API URL (Rest service bellow) Rest service is avalaible at: http://management_ip:8100 Webui service is avalaible at: http://management_ip:8099 Typing http://management_ip:8081/events/test in a web browser should display the message : is running Now that you have a JAVA_HOME set and a customized running instance of Cloudify, you can move to the next step, how to install and configure the driver . If you want to use the provider’s blockStorage feature, in addition to the storage configuration of you cloud, you must make sure to have the property privileged true in all of your compute templates’ definitions. "},{"title":"Components browsing and searching","baseurl":"","url":"/documentation/tosca_ref/components_browse_search.html","date":null,"categories":[],"body":"Alien4Cloud provides ways to browse the uploaded components, with a search engine allowing filters. Users with role COMPONENT_MANAGER can browse and search for components. How to make a simple search On the left of the components list page, there is a search pannel (see figure above: A ). For a simple search, just type the searched text in the seach field and press the magnifier next to it (or press the Enter keybord instead). The result of your research will be displayed on the center pannel (see figure above: B ). How to make a filtered search You might wish to filter your search or results, for there are too many components corresponding to the simple search. Still on the left search pannel, you can select one or more filters (facets). You can also remove them if they do not fit you. Note that when more than one filter are selected, Alien4Cloud applies an AND policy. Component overview After the search, you can have an overview of the component. Just move the mouse on one component and you will have the right pannel display its summary:(see figure above: C ). If it is the one you are looking for, or if you want further informations about it, you can now select it and see its details . "},{"title":"Constraint clause","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/constraints.html","date":null,"categories":[],"body":"A constraint clause defines an operation along with one or more compatible values that can be used to define a constraint on a property’s or parameter’s allowed values. Available constraints The following is the list of recognized operators (keynames) when defining constraint clauses: Operator Type Value type Description equal scalar all Constrains a property or parameter to a value equal to (‘=’) the value declared. greater_than scalar comparable Constrains a property or parameter to a value greater than (‘>’) the value declared. greater_or_equal scalar comparable Constrains a property or parameter to a value greater than or equal to (‘>=’) the value declared. less_than scalar comparable Constrains a property or parameter to a value less than (‘<’) the value declared. less_or_equal scalar comparable Constrains a property or parameter to a value less than or equal to (‘<=’) the value declared. in_range dual scalar comparable Constrains a property or parameter to a value in range of (inclusive) the two values declared. valid_values list all Constrains a property or parameter to a value that is in the list of declared values. length scalar string Constrains the property or parameter to a value of a given length. min_length scalar   string Constrains the property or parameter to a value to a minimum length. max_length scalar string Constrains the property or parameter to a value to a maximum length. pattern regex string Constrains the property or parameter to a value that is allowed by the provided regular expression. The value type comparable refers to integer, float , timestamp and version types, while all refers to any type allowed in the TOSCA simple profile in YAML. Regular expression language in Alien 4 Cloud (not specified in TOSCA currently) is Java regex. Grammar # Scalar grammar <operator> : <scalar_value> # Dual scalar grammar <operator> : [ <scalar_value_1> , <scalar_value_2> ] # List grammar <operator> : [ <value_1> , <value_2> , ... , <value_n> ] # Regular expression (regex) grammar pattern : <regular_expression_value> Example The following example shows how to define a node type with constraints on properties: node_types : fastconnect.nodes.ConstraintSample : properties : property_1 : type : string constraints : - length : 6 property_2 : type : string constraints : - min_length : 4 - max_length : 8 property_3 : type : integer constraints : - in_range : [ 2 , 10 ] property_4 : type : integer constraints : - valid_values : [ 2 , 4 , 6 , 8 , 16 , 24 , 32 ] "},{"title":"Cloud(s) configuration","baseurl":"","url":"/documentation/getting_started/creating_cloud.html","date":null,"categories":[],"body":"Introduction to the cloud concepts In Alien 4 Cloud every deployment is done on what we call a Cloud . Clouds in A4C can represent a real cloud or more often a separated logically deployment entity. For example a cloud can refer to an Amazon configuration using a specific account while another cloud could be configured to work on a specific Tenant on an OpenStack cloud. Using some PaaS Providers like Cloudify 2 you can even configure a set of running machines (that doesn’t have to be VMs) to create a logical set of available resources that Alien 4 Cloud can use to deploy applications. You can create and configure as many clouds as you like to have as many deployment environment as required. PaaS Providers and plugins Alien 4 Cloud is not managing actual runtime state of deployments by itself. In order to do so it delegates runtime to what we call PaaS Providers. A PaaS Provider in A4C is a plugin that is associated with a cloud configured in A4C. Every cloud may use the same PaaS Provider or may use different PaaS Providers. Anyway in order to create clouds (that are required to perform deployments) you have to first upload a PaaS provider plugin (Alien 4 Cloud supports other type of plugins as well but we won’t detail this here). The current recommended plugin to start is leveraging Cloudify as the PaaS Orchestrator tool. Cloudify is OpenSource just like A4C and fits very well with it. We are currently using the version Cloudify 2.7. We will move to Cloudify 3.1 once released as GigaSpaces plan to support TOSCA as an input in cloudify 3.1. Installing Cloudify 2.7 plugin Follow this link in order to find more on installation and configuration of your coud environment using cloudify 2. Using mock plugin If you want to try out Alien 4 Cloud but not use a real cloud for deployments you can use the mock PaaS Provider plugin. This is a plugin that we use for our tests and that mock the PaaS orchestrator. The mock plugin does not allow you to test any of your components as it do not deploy anything or even call your scripts. To do so you should use a real PaaS Provider plugin like cloudify plugin and deploy on a local cloud technology like Virtua Box or Docker (note that docker support will come with support of cloudify 3). Create a cloud Once you have installed a plugin the admin can go on the cloud page and configure cloud. Remember that you can use the Alien 4 Cloud contextual help in order to be guided directly within the application. Manage cloud resources Once created you must configure the cloud. Configuring a cloud requires several step: Configure the properties of the PaaS provider (that depends of the choosen one). Configure cloud resources (images and flavors) used for resources matchin at deployment time. "},{"title":"Customised Blockstorage","baseurl":"","url":"/documentation/cloudify2_driver/custom_blockstorage.html","date":null,"categories":[],"body":" Note that the driver only supports groovy scripts for all these scripts. Some times you might need to provide your own way to manage the storage lifecycle. This is for example if you have a custom way to create, attach, format, mount it. For that, you can provide every node of type tosca.nodes.BlockStorage with the lifcycle operation create and configure . And for the destroy process, you’ll use the delete operation. alien.test.nodes.UbuntuBlockStorage : derived_from : tosca.nodes.BlockStorage description : > A custom storage for Ubuntu OS. interfaces : Standard : create : scripts/createAttach.groovy configure : scripts/formatMount.groovy delete : scripts/unmountDelete.groovy [ ... ] Create and attach Provide your custom way to create and attach the storage to your compute in the create TOSCA Standard’s operation. Environment variables In addition to the provided base node environment variables SELF, HOST, SERVICE_NAME : Keyword Description volumeId if provided, the Id of the volume to attach. This might be null storageTemplate The Id of the storage template to use to create a volume, base on the size provided. This is never null. Return The script must return a map <String –> String> containing the keys: volumeId : id of the created (or provided) volume, device : device name on which the volume is attached Example import org.cloudifysource.utilitydomain.context.ServiceContextFactory def context = ServiceContextFactory . getServiceContext () def device = \"/dev/vdb\" //Creating the volume if ( volumeId == null ){ volumeId = context . storage . createVolume ( storageTemplate ) } //attaching the volume context . storage . attachVolume ( volumeId , device ) //return the map return [ volumeId: volumeId , device: device ] Format and mount Provide your custom way to format and mount the storage on your compute in the configure TOSCA Standard’s operation. Environment variables In addition to the provided base node environment variables SELF, HOST, SERVICE_NAME : Keyword Description device device name on which the volume is attached Return The script must return a string value: location : location path where the device is mounted on the compute Example import org.cloudifysource.utilitydomain.context.ServiceContextFactory def context = ServiceContextFactory . getServiceContext () def location = \"/mountTest\" denew AntBuilder (). sequential { chmod ( dir: \"${context.serviceDirectory}/scripts\" , perm: \"+x\" , includes: \"*.sh\" ) exec ( executable: \"${context.serviceDirectory}/scripts/formatStorage.sh\" , failonerror: \"true\" ) { arg ( value: \"${device}\" ) } mkdir ( dir: location ) exec ( executable: \"${context.serviceDirectory}/scripts/mountStorage.sh\" , failonerror: \"true\" ) { arg ( value: \"${device}\" ) arg ( value: \"${location}\" ) } } //return the mounted path name return location Unmount and delete Provide your custom way to unmount and/or delete the storage in the delete TOSCA Standard’s operation. Environment variables In addition to the provided base node environment variables SELF, HOST, SERVICE_NAME : Keyword Description volumeId if provided, the Id of the attached volume. device device name on which the volume is attached Return No need to return anything for this script. Example import org.cloudifysource.utilitydomain.context.ServiceContextFactory def context = ServiceContextFactory . getServiceContext () println \"Storage volume: volumeId <${volumeId}>, device <${device}>\" println \"deletable-unmountDelete.groovy: unmounting storage volume... \" context . storage . unmount ( device ) println \"deletable-unmountDelete.groovy: detaching storage volume... \" context . storage . detachVolume ( volumeId ) "},{"title":"Definitions document","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/definitions_file.html","date":null,"categories":[],"body":"The root element of a definition file is called the Service Template. A TOSCA Definitions YAML document contains element definitions of building blocks for cloud application, or complete models of cloud applications. This section describes the top-level structural elements (i.e., YAML keys) which are allowed to appear in a TOSCA Definitions YAML document. Keynames A TOSCA Definitions file contains the following element keynames: Keyname Required Description tosca_definitions_version yes Defines the version of the TOSCA Simple Profile specification the template (grammar) complies with. tosca_default_namespace no Defines the namespace of the TOSCA schema to use for validation. template_name yes* Declares the name of the template. template_author no Declares the author(s) of the template. template_version yes* Declares the version string for the template. description no Declares a description for this Service Template and its contents. imports no Declares import statements external TOSCA Definitions documents (files). dsl_defintions no Declares optional DSL-specific definitions and conventions. For example, in YAML, this allows defining reusable YAML macros (i.e., YAML alias anchors) for use throughout the TOSCA Service Template. inputs no Defines a set of global input parameters passed to the template when its instantiated. This provides a means for template authors to provide points of variability to users of the template in order to customize each instance within certain constraints. node_templates no Defines a list of Node Templates that model the components of an application or service’s topology within the Service Template. relationship_templates no Defines a list of Relationship Templates that are used to model the relationships (e.g., dependencies, links, etc.) between components (i.e., Node Templates) of an application or service’s topology within the Service Template. node_types no This section contains a set of node type definitions for use in service templates. Such type definitions may be used within the node_templates section of the same file, or a TOSCA Definitions file may also just contain node type definitions for use in other files. relationship_types no This section contains a set of relationship type definitions for use in service templates. Such type definitions may be used within the same file, or a TOSCA Definitions file may also just contain relationship type definitions for use in other files. capability_types no This section contains an optional list of capability type definitions for use in service templates. Such type definitions may be used within the same file, or a TOSCA Definitions file may also just contain capability type definitions for use in other files. artifact_types no This section contains an optional list of artifact type definitions for use in service templates. Such type definitions may be used within the same file, or a TOSCA Definitions file may also just contain capability type definitions for use in other files. outputs no This optional section allows for defining a set of output parameters provided to users of the template. For example, this can be used for exposing the URL for logging into a web application that has been set up during the instantiation of a template. groups no This is an optional section that contains grouping definition for node templates. (*) In Alien 4 Cloud the template name and versions are required as we supports versioning of the templates and indexing of elements in a catalog. In TOSCA specification they are optional. Grammar The overall structure of a TOSCA Service Template and its top-level key collations using the TOSCA Simple Profile is shown below: tosca_definitions_version : # Required TOSCA Definitions version string tosca_default_namespace : # Optional. default namespace (schema, types version) template_name : # Optional name of this service template template_author : # Optional author of this service template template_version : # Optional version of this service template description : A short description of the definitions inside the file. imports : # list of import statements for importing other definitions files dsl_definitions : # list of YAML alias anchors (or macros) inputs : # list of global input parameters node_templates : # list of node templates relationship_templates : # list of relationship templates node_types : # list of node type definitions capability_types : # list of capability type definitions relationship_types : # list of relationship type definitions artifact_types : # list of artifact type definitions groups : # list of groups defined in service template outputs : # list of output parameters tosca_definitions_version This required element provides a means to include a reference to the TOSCA Simple Profile specification within the TOSCA Definitions YAML file. It is an indicator for the version of the TOSCA grammar that should be used to parse the remainder of the document. Keyword tosca_definitions_version Grammar tosca_definitions_version : <tosca_simple_profile_version> Examples: TOSCA Simple Profile version 1.0 specification using the defined namespace alias: tosca_definitions_version : tosca_simple_yaml_1_0_0 TOSCA Simple Profile version 1.0 specification using the fully defined (target) namespace: tosca_definitions_version : http://docs.oasis-open.org/tosca/simple/1.0 template_name This optional element declares the optional name of service template as a single-line string value. Keyword template_name Grammar template_name : <name string> Example template_name : My service template Notes Some service templates are designed to be referenced and reused by other service templates. Therefore, in these cases, the template_name value SHOULD be designed to be used as a unique identifier through the use of namespacing techniques. template_author This optional element declares the optional author(s) of the service template as a single-line string value. Keyword template_author #### Grammar template_author : <author string> Example template_author : My service template template_version This element declares the optional version of the service template as a single-line string value. Grammar template_version : <version> Example template_version : 2.0.17 Some service templates are designed to be referenced and reused by other service templates and have a lifecycle of their own. Therefore, in these cases, a template_version value SHOULD be included and used in conjunction with a unique template_name value to enable lifecycle management of the service template and its contents. description This optional element provides a means to include single or multiline descriptions within a TOSCA Simple Profile template as a scalar string value. imports This optional element provides a way to import a block sequence of one or more TOSCA Definitions documents. TOSCA Definitions documents can contain reusable TOSCA type definitions (e.g., Node Types, Relationship Types, Artifact Types, etc.) defined by other authors. This mechanism provides an effective way for companies and organizations to define normative types and/or describe their software applications for reuse in other TOSCA Service Templates. In Alien 4 Cloud you can import libraries from the repository instead of having to package every required elements within your archives. This also allows a better management of versioning and dependencies. In order to support this scenario the import element supports an additional non-normative definition. Of course when you export artifacts from Alien 4 Cloud you can ask Alien 4 Cloud to export a pure normative package (Alien will package all elements required together in a single archive and use normative relative imports). Grammar imports : - <tosca_definitions_file_1> - ... - <tosca_definitions_file_n> Alien 4 Cloud specific grammar for catalog imports based on Definitions template names and versions. imports : - <tosca_template_name_1>:<tosca_template_version_1> - ... - <tosca_template_name_n>:<tosca_template_version_n> Example # An example import of definitions files from a location relative to the # file location of the service template declaring the import. imports : - relative_path/my_defns/my_typesdefs_1.yaml - ... - relative_path/my_defns/my_typesdefs_n.yaml Alien 4 Cloud specific. imports : - <tosca-normative-types>:<1.0.0> - ... - <apache-server>:<2.0.3> inputs This optional element provides a means to define parameters, their allowed values via constraints and default values within a TOSCA Simple Profile template. This section defines template-level input parameter section. * Inputs here would ideally be mapped to BoundaryDefinitions in TOSCA v1.0. * Treat input parameters as fixed global variables (not settable within template) * If not in input take default (nodes use default) Grammar inputs : <property_definition_1> ... <property_definition_n> Examples Simple example without any constraints: inputs : fooName : type : string description : Simple string typed property definition with no constraints. default : bar Example with constraints: inputs : SiteName : type : string description : string typed property definition with constraints default : My Site constraints : - min_length : 9 The parameters (properties) that are listed as part of the inputs block could be mapped to PropertyMappings provided as part of BoundaryDefinitions as described by the TOSCA v1.0 specification. node_templates This element lists the Node Templates that describe the (software) components that are used to compose cloud applications. #### Grammar node_templates : <node_template_defn_1> ... <node_template_defn_n> A.5.3.8.3 Example node_templates: my_webapp_node_template : type : WebApplication my_database_node_template : type : Database The node templates listed as part of the node_templates block can be mapped to the list of NodeTemplate definitions provided as part of TopologyTemplate of a ServiceTemplate as described by the TOSCA v1.0 specification. node_types This element lists the Node Types that provide the reusable type definitions for software components that Node Templates can be based upon. Grammar node_types : <node_types_defn_1> ... <node_type_defn_n> Example node_types : my_webapp_node_type : derived_from : WebApplication properties : my_port : type : integer my_database_node_type : derived_from : Database capabilities : mytypes.myfeatures.transactSQL The node types listed as part of the node_types block can be mapped to the list of NodeType definitions as described by the TOSCA v1.0 specification. relationship_types This element lists the Relationship Types that provide the reusable type definitions that can be used to describe dependent relationships between Node Templates or Node Types. Grammar relationship_types : <relationship_type_defn_1> ... <relationship type_defn_n> Example relationship_types : mycompany.mytypes.myCustomClientServerType : derived_from : tosca.relationships.HostedOn properties : # more details ... mycompany.mytypes.myCustomConnectionType : derived_from : tosca.relationships.ConnectsTo properties : # more details ... capability_types This element lists the Capability Types that provide the reusable type definitions that can be used to describe features Node Templates or Node Types can declare they support. Grammar capability_types : <capability_type_defn_1> ... <capability type_defn_n> Example capability_types : mycompany.mytypes.myCustomEndpoint : derived_from : tosca.capabilities.Endpoint properties : # more details ... mycompany.mytypes.myCustomFeature : derived_from : tosca.capabilites.Feature properties : # more details ... groups The group construct is a composition element used to group one or more node templates within a TOSCA Service Template. Grammar groups : <group_name_A> : <node_template_defn_A_1> ... <node_template_defn_A_n> <group_name_B> <node_template_defn_B_1> ... <node_template_defn_B_n> Example node_templates : server1 : type : tosca.nodes.Compute # more details ... server2 : type : tosca.nodes.Compute # more details ... server3 : type : tosca.nodes.Compute # more details ... groups : server_group_1 : members : [ server1 , server2 ] policies : - anti_collocation_policy : # specific policy declarations omitted, as this is not yet specified outputs This optional element provides a means to define the output parameters that are available from a TOSCA Simple Profile service template. Grammar outputs : <property_definitions> Example outputs : server_ip : description : The IP address of the provisioned server. value : { get_attribute : [ my_server , ip_address ] } "},{"title":"Function definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/function_definition.html","date":null,"categories":[],"body":"Work in progress, details the functions that can be applied to properties and function input parameters. A function definition defines a named function to evaluate at runtime, and that can be used as property, attribute or input parameter. It is used to dynamically retrieve a value from property definition defined on an entity. Reserved function keywords The following keywords may be used in some TOSCA function in place of a TOSCA Node or Relationship Template name. They will be interpreted when evaluation the function at runtime. Keyword Valid context Description SELF Node Template or Relationship Template Node or Relationship Template instance that contains the function at the time the function is evaluated. SOURCE Relationship Template only Node Template instance that is at the source end of the relationship that contains the referencing function. TARGET Relationship Template only Node Template instance that is at the target end of the relationship that contains the referencing function. HOST Node Template only Node that “hosts” the node using this reference (i.e., as identified by its HostedOn relationship). Functions are: get_porperty get_attribute "},{"title":"get_attribute","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/get_attribute_definition.html","date":null,"categories":[],"body":"The get_attribute function is used to retrieve the values of named attributes declared by the referenced node or relationship template name. Use this function for inputs parameters. Keyname Type Required Description modelable_entity_name string yes The required name of a modelable entity (e.g., Node Template or Relationship Template name) as declared in the service template that contains the named property definition the function will return the value from.Can be one of the reserved keywords: SELF, SOURCE, TARGET, HOST attribute_name string yes Name of the attribute definition the function will return the value from. Grammar <input_name> : { get_attribute** : [ <modelable_entity_name | SELF | SOURCE | TARGET | HOST> , <attribute_name> ] } Example The following example shows how to define an input parameter on relationship using get_attribute function: relationship_types : fastconnect.relationship.FunctionSample interfaces : configure : add_target : inputs : TARGET_IP : { get_attribute : [ TARGET , ip_address ] } implementation : add_target.sh "},{"title":"get_property","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/get_property_definition.html","date":null,"categories":[],"body":"The get_property function is used to retrieve property values between modelable entities defined in the same service template. Use this function for inputs parameters. Keyname Type Required Description modelable_entity_name string yes The required name of a modelable entity (e.g., Node Template or Relationship Template name) as declared in the service template that contains the named property definition the function will return the value from.Can be one of the reserved keywords: SELF, SOURCE, TARGET, HOST property_name string yes Name of the property definition the function will return the value from. Grammar <input_name> : { get_property : [ <modelable_entity_name | SELF | SOURCE | TARGET | HOST> , <property_name> ] } Example The following example shows how to define an input parameter using get_property function: node_types : fastconnect.nodes.FunctionSample : properties : myName : type : string interfaces : Standard : configure : inputs : MY_NAME : { get_property : [ SELF , myName ] } implementation : config-my-name.sh "},{"title":"Getting started","baseurl":"","url":"/documentation/getting_started/getting_started.html","date":null,"categories":[],"body":"In order to start using alien 4 cloud you have to download Alien. Two versions are available: standalone : starts an embedded jetty server. deployable : war file that can be deployed within a war container. We recommend using the standalone version. Starting Alien 4 Cloud standalone Once downloaded you can start alien 4 cloud using the following command. java -jar alien4cloud-ui-VERSION-standalone.war Once started you can access alien 4 cloud using your browser at http://localhost:8088/ . Default administrator user is admin and password admin . For production settings we recommend you to read the advanced configuration section. "},{"title":"ALIEN 4 Cloud","baseurl":"","url":"/index.html","date":null,"categories":[],"body":" Application LIfecycle ENabler 4 Cloud: Application Management on the cloud for enterprise. More about ALIEN for Cloud » "},{"title":"ALIEN 4 Cloud","baseurl":"","url":"/community/index.html","date":null,"categories":[],"body":" Twitter We are on on twitter , so feel free to follow us and get the latest news on Alien 4 Cloud. Source code ALIEN 4 Cloud is open source under the Apache 2 License. The code is hosted on GitHub . You are welcome to clone, fork and submit pull-requets. The documentation is also hosted on github and you can also help us to improve it. IRC channel If you need help now, or want to discuss matters in real time, use the #alien4cloud channel on irc.freenode.net ( webchat.freenode ). Issues Issues and feature requests can be filled in directly on the project's GitHub issue management . "},{"title":"Components and TOSCA ref.","baseurl":"","url":"/documentation/tosca_ref/index.html","date":null,"categories":[],"body":"This section contains details on how to configure new middlewares, relationships and other elements form Alien 4 Cloud. Alien 4 Cloud is designed so you can easily add your own components and leverage your existing scripts, puppet or chef recipes, using a simple YAML based DSL. TOSCA Alien 4 Cloud is compliant with OASIS’s TOSCA standard to model it’s different components (nodes, relationships, capabilities and requirements). In order to define components in TOSCA you can use the XML or YAML profile (TOSCA Simple Profile). We recommend using the simple profile and thus this documentation describe only the way to configure elements using the simple profile. Alien 4 Cloud only supports TOSCA Simple Profile in YAML. Latest supported version is TOSCA Simple Profile in YAML working draft 03. "},{"title":"About Alien4Cloud","baseurl":"","url":"/alien_about/index.html","date":null,"categories":[],"body":" Alien4Cloud means Application LIfecycle ENablement for Cloud. It is a project started by FastConnect in order to help enterprises adopting the cloud for their new or even existing applications in an Open way meaning with Open-Source model and standardization support in mind. Why Cloud Computing is becoming prime development and deployment model for a number of applications. New applications being developed want to benefit from the agility and sometimes cost reduction implied by usage of Cloud technologies. Existing applications want to benefit as well from this model to be able to allow development and operations teams, managing the applications, to accelerate new features or maintenance pace. This requires to implement agility principles and leverage proper tools, not only in development, but as well on the deployment phase along all the application lifecycle. As well agility is reached when proper collaboration between Dev and Ops teams, and their business sponsor, is achieved. Even if a large number of solutions exist in the Cloud ecosystem, the ecosystem is not consolidated. Architectures, APIs, technologies and infrastructures are still evolving a lot. It leaves a lot of choice to the one willing to develop and deploy applications in the Cloud, but very often, the will to reach agility creates a lock-in to the choosen provider at some level : SaaS, PaaS or IaaS. Knowing the investment term in the Applications from development to deployment (usually several years), and the legacy, it is important to protect the investment in the Application lifecycle, from moving parts, at any level possible. What Alien4Cloud aims at addressing some of these problems by providing the following capabilities : Ease the design and portability of Applications by leveraging TOSCA (an emerging standard driven by OASIS foundation) Isolate the application evolution from deployment technologies and infrastructures, allowing to integrate with any deployment layer and infrastructure Accelerate Application Infrastructure Design and improve reusability by providing a Components and Blueprints catalog Ease collaboration between Development and Deployment teams across the Application lifecycle in creating the Components and Blueprints to fill the catalog Integrate with existing Enterprise systems (Dev and Ops) through REST API and pluggable strategies Check current roadmap for details on where we are and where we go. Standard support Alien4Cloud supports OASIS TOSCA an emerging standard addressing applications portability in the cloud. We believe that applications cloud enablement should be done in an open way, free of any lock-in. No lock-in meaning that the application should freely move from one environment to the other with smallest effort possible. Therefore, it needs to abstract itself from the underlying infrastructure technical adherence, and define its infrastructure requirements and architecture, independently from each Cloud Provider’s Infrastructure Catalog. If not done, even if, technical compability between vendors could exist in theory (yet to be confirmed by reality), Infrastructure Catalog alignment between providers is very unlikely to happen as each provider is focusing in delivering best value to its customers and does not spend time aligning with others, especially when they may be competitors. As an analogy, can you easily compare your Telecom providers offerings ? We bet that the same will happen with Cloud providers, and it has already started. TOSCA enables the expression of Application Requirements on the Infrastructure and its QOS/SLA, in an open way, opening the door to optimized placement of Applications in the Cloud Infrastructures based on customer choice at its heart. We know about Infrastructure As Code, with TOSCA, we enter in to the era of “Application Requirements as Code” easing Application lifecycle management across several Cloud infrastructures. By increasing service and application portability in a vendor-neutral ecosystem, TOSCA will enable : Portable deployment to any compliant cloud Smoother migration of existing applications to the cloud Flexible bursting (consumer choice) Dynamic, multi-cloud provider applications Open-Source We decided to build Alien4Cloud and give it to the community in order to allow Application Requirements modelling in a TOSCA format, in a collaborative way, between all participants involved in Application Infrastructure Requirements definition. It is provided with an Apache 2 license in order to favour contributions from external teams or individuals. Please check our Contribute page to see how you can help. What it is not Alien4Cloud focuses on Design, Collaboration, Application Lifecycle Management and later Governance, but leverages other existing open source projects that help orchestrating cloud applications and which focus on runtime aspects such as Cloudify . Alien4Cloud does not aim to provide applications deployment runtime. We believe that there are already a number of viable options there (some of them not being TOSCA compliant, btw) and we want to integrate more than replace. We do it in an open way through plug-in approach to allow you to leverage your best tools or skills. Status Even if the project is still in its BETA phase, we already use Alien4Cloud, in real-life projects inside FastConnect in order to provide self-service, industrialisation and collaboration in the design and management of applications blueprints. "},{"title":"Cloudify 2 PaaS Provider","baseurl":"","url":"/documentation/cloudify2_driver/index.html","date":null,"categories":[],"body":"ALIEN allows, via the plugin mechanism, to provide extensions. An extension could be a driver to manage a specific cloud, rendering ALIEN to be able to perfom operations on the related cloud. This section gives a focus to Cloudify driver for ALIEN, a plugin to manage deployment on various cloud using the PaaS factory Cloudify . In this documentation, we will assume you have access to the GUI of a running instance of ALIEN 4 Cloud. Also, make sure you have the proper rights when needed. Start with the prerequisites . "},{"title":"ALIEN 4 Cloud - Documentation","baseurl":"","url":"/documentation/index.html","date":null,"categories":[],"body":"Welcome on Alien 4 Cloud documentation. You will find here resources to use alien 4 cloud. This includes: Concepts of Alien 4 Cloud Installation and configuration Creation of cloud services archives (including an overview of OASIS TOSCA concepts) ALIEN for Cloud High level concept ALIEN for Cloud (Application LIfecycle ENabler for cloud) is a tool that aims to provide management for enterprise cloud and help enterprise to onboard their applications to a cloud, leverage it’s benefits and, based on project constraints, reach continuous delivery. As moving to the cloud for an enterprise is a structural change, ALIEN for Cloud leverage the TOSCA standard that is the most advanced and supported standard for the cloud. The Goal of ALIEN for Cloud is to enable the benefits of a cloud migration in enterprise by easing the DevOps collaboration taking in account the capabilities of each of the IT expert in the enterprise. This is done by providing a single platform where every expert can contribute and share it’s effort and feedback with others. ALIEN provides three main features: Composable PaaS & DevOps collaboration Application lifecycle enablement Cloud governance Collaboration Collaboration in ALIEN for cloud is done by giving the ability to each expert to work on it’s field of expertise, and for other experts to benefits from his work and reuse it in a simple and declarative way. TOSCA standard is a great start point to enable such collaboration. ALIEN for Cloud add user roles management in order to increase the ability to easily collaborate on the platform. Composable PaaS Topology definition in ALIEN for cloud The first aspect of ALIEN for cloud is related to the core of the cloud interoperability: defining an application topology that we can deploy on any cloud. It takes in account critical requirements for an enterprise: reusability extensibility flexibility consistency evolvability (Very) Quick introduction to TOSCA In the TOSCA model, an Application Topology is created by declaration of some components (nodes) instances (templates) based on some existing types. The types defines the meta-model of a component (properties, operations, capabilities and requirements) and it’s implementation artifacts. A TOSCA container can then deploy the declared topology on a cloud and orchestrated it. Collaboration in a TOSCA model is easy as someone that want’s to build an application topology can reuse components created by the experts. Typically an application architect will be able to reuse software and cloud components defined by the operational teams in the enterprise. Application lifecycle enablement Alien 4 Cloud allows users to define multiple versions and environments for an application, each environment has an associated version allowing you to move a version from a development environment to the production environment through all required environments in your lifecycle. Cloud governance As ALIEN for cloud manages the topologies of applications as well as their deployments, it keeps many informations that will enable governance of your cloud, a better vision of your applications, their lifecycle, the ability of your projects to deliver fast etc. It enables features like rationalisation of the SI capacity planning management of middleware support and expiration dates etc. "},{"title":"Roadmap","baseurl":"","url":"/roadmap/index.html","date":null,"categories":[],"body":" The following represents current view of Alien4Cloud development team of its product development cycle and future directions. It is intended for information purposes only, and should not be interpreted as a commitment, though we do our best to reach the dates and features set mentioned below. We know it may need to be clarified, and this will improve with time. Please note that we deliver intermediate releases in Alien4Cloud GitHub repo , every 2 weeks, in order to get feedback on features while still in development. January 2015, Version 1, In progress Tosca Simple Profile - final Application Lifecycle Management Workspace support including pluggable limitation policies Cloudify managers managed from Alien 4 Cloud Audit features Planned features for 2015, still being defined Cloudify 3 support Docker support Apache Brooklyn support Pluggable Application version update strategies Custom workflows designer More dashboards & alerts IT Social network features Dynamic scalability (can be added earlier if needed) If you want to propose other features and/or if you are willing to contribute, please contact us . "},{"title":"Release Notes","baseurl":"","url":"/release_notes/index.html","date":null,"categories":[],"body":""},{"title":"Developer Guide","baseurl":"","url":"/developer_guide/index.html","date":null,"categories":[],"body":"ALIEN has been designed to be easily extended and integrated with other systems. It uses a plugin mechanism in order to provide extensions, and the REST API makes it easy to integrate. The REST API documentation can be browsed directly on ALIEN’s server (http:// /rest-api/) and this section will not provides more details about it. This section gives a focus to ALIEN extensions through the plugin mechanism. In order to understand plugins it is important to know how ALIEN is designed and how plugins are managed by ALIEN. "},{"title":"Inputs and others variables","baseurl":"","url":"/documentation/cloudify2_driver/inputs_env_vars.html","date":null,"categories":[],"body":"Your implementations scripts can be defined with inputs. Find here how to properly define an input, and what other information is available in the execution environment. We will have for illustrations purposes a topology consisting of one Compute node, one Tomcat and two War nodes. input parameters Follow the parameter definition section for how to define your input parameters. The defined inputs are evaluated if needed at runtime, and set as environment variables. Thus, you can access them using their defined name. relationship type alien.relationships.cloudify.WarHostedOnTomcat , defined with a post_configure_source script:. alien.relationships.cloudify.WarHostedOnTomcat : [ ... ] interfaces : configure : post_configure_source : inputs : CONTEXT_PATH : { get_property : [ SOURCE , contextPath ] } TOMCAT_IP : { get_attribute : [ TARGET , ip_address ] } implementation : relationshipScripts/warHostedOnTomcat_post_configure_source.groovy [ ... ] Other available environment variables Prior to the inputs parameters, some useful informations are available in the script execution environment: Keyword Node Template Relationship Template Description Example SELF Yes No Node name . War, serveurWeb HOST Yes No Name of the node that “hosts” the current node. For node War: Tomcat SERVICE_NAME Yes No Cloudify service name in which the node related to the script is hosted (the root compute node name without spaces and in lowercase). for War and War_2: serveurweb SOURCE_NAME No Yes Node name of the source of the relationship. War, War_2 SOURCE No Yes Node id of the source of the relationship. The id is the node name without spaces and in lowercase, postfixed with the instance id War:(war_1 or war_2), War_2:(war_2_1 or war_2_2) SOURCE_SERVICE_NAME No Yes Cloudify service name in which the source node related to the relationship script is hosted (the root compute node name without spaces and in lowercase). for War and War_2: serveurweb SOURCES No Yes Comma-separated list of Node id of all the nodes currently the source of the relationship. war_1,war_2,war_n TARGET_NAME No Yes Same as SOURCE_NAME, but for the target. Tomcat TARGET No Yes Same as SOURCE, but for the target. tomcat_1 or tomcat_2 TARGET_SERVICE_NAME No Yes Cloudify service name in which the target node related to the relationship script is hosted (the compute nodeId). for Tomcat: serveurweb TARGETS No Yes Comma-separated list of Node id of all the nodes currently target of the relationship. tomcat_1,tomcat_2,tomcat_n When a node (source node in case of a relationship) has some defined artifacts (overridable or not), their relative location paths are available as environment variables ( their names ) of the operations scripts. Relationships and get_attribute inputs the input TOMCAT_IP , as an environment variable that will hold the IP address of the target being processed will be provided to the warHostedOnTomcat_post_configure_source.groovy script. In addition, the IP addresses of all current tomcat members will be provided as environment variables with a naming scheme of tomcat_{instanceId}_TOMCAT_IP . Assuming that the aplication is deployed with 5 instances and the instance 5 is the current one, the following environment variables (plus potentially more variables) would be provided to the warHostedOnTomcat_post_configure_source.groovy script: TARGET = tomcat_5 TARGETS = tomcat_1 , tomcat_2 , tomcat_3 , tomcat_4 , tomcat_5 TOMCAT_IP = 10.0 . 0.5 tomcat_1_TOMCAT_IP = 10.0 . 0.1 tomcat_2_TOMCAT_IP = 10.0 . 0.2 tomcat_3_TOMCAT_IP = 10.0 . 0.3 tomcat_4_TOMCAT_IP = 10.0 . 0.4 tomcat_5_TOMCAT_IP = 10.0 . 0.5 Example Let see the example of the the node War_2: it has an overridable artifact named war_file alien.nodes.cloudify.War [...] artifacts : - war_file : warFiles/helloWorld.war type : alien.artifacts.WarFile [ ... ] This code snippet shows how to use inputs and others informations available in the execution environment of the relationship implementation script (groovy script): def context = ServiceContextFactory . getServiceContext () //printing the env vars println \"warHostedOnTomcat_post_configure_source<${SOURCE}> start.\" println \"warHostedOnTomcat_post_configure_source<${SOURCE}>: Inputs are:\" println \"contextPath : ${CONTEXT_PATH}; tomcatIp : ${TOMCAT_IP}\" println \"Target: ${TARGET}; Target_Service_Name: ${TARGET_SERVICE_NAME},\\n Source: ${SOURCE}, Source_Service_Name: ${SOURCE_SERVICE_NAME}\" println \"SOURCES: ${SOURCES}, TARGETS: ${TARGETS}\" println \"war_file Artifact path: ${war_file}\" //checking and using the war_file source artifact if (! war_file ) return \"warUrl is null. So we do nothing.\" def warUrl = \"${context.serviceDirectory}/../${war_file}\" def command = \"${TARGET_NAME}_updateWarOnTomcat\" println \"warHostedOnTomcat_post_configure_source<${SOURCE}> invoking ${command} custom command on target tomcat...\" def service = context . waitForService ( TARGET_SERVICE_NAME , 60 , TimeUnit . SECONDS ) def currentInstance = service . getInstances (). find { it . instanceId == context . instanceId } currentInstance . invoke ( command , \"url=${warUrl}\" as String , \"contextPath=${CONTEXT_PATH}\" as String ) println \"warHostedOnTomcat_post_configure_source<${SOURCE}> end\" return true Note that for groovy case, the inputs and others are set to the script binding, rather than into the execution environment. This makes them available by typing their names as if they where some groovy var already declared(ex: TOMCAT_IP, war_file). If you want to check the existence of any of them, just use the snippet: binding.variables.containsKey(env_var_name_to_check) . In sh case, access and use them as environment variables. Note the usage of ${context.serviceDirectory}/../${war_file} as the artifact path given ( war_file ) is a relative one. "},{"title":"Installing and configuring","baseurl":"","url":"/documentation/cloudify2_driver/install_config.html","date":null,"categories":[],"body":"Find here how to install and configure the Cloudify 2 driver. Download First step of course is to download the plugin. last stable version works with the latest stable alien version. last build version works with the latest build alien version. Install The driver is packaged as an ALIEN plugin, install it in admin > plugins of your running instance of ALIEN. Configure You need to create a cloud and configure it. Creating the cloud Login as an admin, and create a cloud: admin > clouds > New Cloud . As PaaS provider for this cloud, make sure to select Cloudify 2 PaaS Provider from the list. Validate Configuring the cloud On the cloud list, select and click on the newly created cloud, then go to the configuration tab. Conection Configuration : Remember the REST API URL you were told to note when bootstraping your cloud with Cloudify, here is the place you’ll need it. Fill the “Cloudify URL” with it, and eventually provide a login (username / password) for the access. Compute templates : Here you have to configure the computes templates avalaibles in your cloud. Make sure the Identifier match exactly one computes defined in your Cloudify clouds’s computes templates. You can save the configuration, switch back to the Details tab and enable the cloud by clicking on the Enable cloud button. The cloud can now be used to deploy an application. You might want to know how the driver impacts the TOSCA archives . "},{"title":"Interface definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/interface_definition.html","date":null,"categories":[],"body":"An interface definition defines a named interface that can be associated with a Node or Relationship Type. Keynames Keyname Type Required Description inputs string no The optional list of input parameter definitions. description string no Alien 4 Cloud specific key to specify the description of the interface. Current implementation of Alien 4 Cloud doesn’t take in account inputs global to an interface but only inputs specified on opertions. Grammar <interface_definition_name> : inputs : <parameter_definitions> <operation_definition_1> ... <operation_definition_n> Example The following example shows how to define a node type with operation: node_types : fastconnect.nodes.OperationSample : interfaces : Standard : desciption : Normative interface that defines a node standard lifecycle. create : /scripts/install.sh configure : description : This is the configuration description. implementation : /scripts/setup.sh inputs : value_input : 4 "},{"title":"ALIEN internal architecture","baseurl":"","url":"/developer_guide/internal-architecture.html","date":null,"categories":[],"body":"ALIEN is an AngularJS (front) + Spring (back) web-application. Plugins for ALIEN are managed as singular Spring applications context that all share the same parent context (ALIEN core application context). Each plugin uses it’s own classloader to ensure that they don’t collide with each others. Here also all of the plugin’s classloaders have a common parent classloader which is ALIEN’s core classloader. "},{"title":"LAMP Stack Tutorial","baseurl":"","url":"/documentation/getting_started/lamp_stack.html","date":null,"categories":[],"body":" This full stack application is still under construction / definition . You can follow it right now for a first jump into A4C but it will surely change in next weeks. We will enhance it trying to show the best way and the recommended granularity to target the best component reusability . This tutorial is based on the well known opensource stack LAMP and aims at getting started with a “real application case”. We will see all steps to go through the stack component definition and have a runnable example. Regarding TOSCA component definition we are using the WD03 version for this tutorial. There is our full alien context to give a try to this tutorial : A4C element Usage TOSCA base types 1.0.0.WD03 A4C WD03 tosca-notmative-types A4C Release 1.0.0-SM18 Standalone WAR or WAR A4C Cloudify2 Driver 1.0.0-SM18 alien4cloud-cloudify2-provider 1.0.0-SM18 TOSCA base types Basicly to build our full application (topology), we will have a set of basic components defined in TOSCA. You will have to inject first this set of components in A4C and then inject your own. More details about normative types . TOSCA definition is in constant evolution, so be sure you are using our fixed implementation given just above. Our components We will basicly define our components and other “relational” items to link those components. This is the main component list : APACHE HTTP Server : http webserver to serve your website MySQL : relational datbase management system (RDBMS) PHP : server-side language used to interact with the database working with your html files This is the basic stack for a LAMP environment and in A4C context we will add one more components : Wordpress : this components will allow to install the Wordpress CMS on the Apache HTTP Server. Wordpress also need a PHP and a Mysql database. Server hosting The L in LAMP stand for Linux, so for our tutorial we assume that we’re working with Ubuntu 14.04 distribution as server. You must have an image on your targeted cloud based on it. We assume that you have an image in your cloud based on Ubuntu 12.04 or 14.04. BlockStorage To persist your data even after your application is undeployed, we will use this default component described in tosca base type wd02 and that allow us to have a volume created, mounted and attached to our server host. MySQL data will be stored on this volume. "},{"title":"Component Apache HTTP","baseurl":"","url":"/documentation/getting_started/lamp_stack_apache.html","date":null,"categories":[],"body":"Apache HTTP server is a free software of the Apache software Foundation, created in 1995. Apache is the most popular web server on internet and the web server of LAMP bundle. Used version for this tutorial : Apache HTTP Server Definition In the definitions folder, we need to write the TOSCA description of our component. It’s also a YAML file use to describe your component. The first line is the TOSCA definition version of the file. The second is a text description of the component. The tags icon is optional. Namming / description TOSCA assumes the existence of a normative base type set. The TOSCA type of Apache is the tosca.nodes.WebServer . Properties The Apache recipe has only two properties : Property Usage Comment version Mention the Apache HTTP Server version Constant version in our example (v2.4). port Port where to expose the Apache HTTP service The default port is : 80 . You can change it of course without using an already used one. document_root The Root Directory of apache2 The default value is : /var/www Lifecycle and related scripts In the interfaces we defined the script used to create the node. In our case we just use the create operation, see the documentation to see all possible operations. In the artifact, we define the folder that contains the script. As we are using Groovy artifact, we defined this artifact at the end of file. Operation Usage Comment create Executed script to install your apache http server on the Compute Through apt-get on ubuntu image start Start apache2 Restart apache2 if it’s already launched start_detection Detect if apache2 is running Test the port of apache2 Optional : To test this Apache recipe, you could create a simple Topology with a Compute and an Apache : With a well configured PaaS Provider , you will have an Apache HTTP Server deployed on a server and ready to use. "},{"title":"Stack Application Topology","baseurl":"","url":"/documentation/getting_started/lamp_stack_application.html","date":null,"categories":[],"body":"On this page we will create our topology representing the LAMP stack. Follow instructions step by step and at the end you will have your stack up and running. To be more concret we will use the Wordpress component to install a real CMS. Prerequisites Get, checkout, download all components listed in the main page of this tutorial Import all components in A4C We assume that you are running the A4C you have downloaded in standalone version Once you are logged as admin , you will have the menu on top, select then the Components item You can also see here how to upload your component Configure your cloud plugin PaaS Provider Then compose you topology following the next steps Point 2 : on each page on the right top corner you have a button with a question mark [?]. Click to start a tour to explain what you can do in the current page and how to do it. Create the topology for the Wordpress application We have explained all components of our LAMP stack. Now, we will use these components to deploy a Wordpress on a cloud. To begin just for on Applications menu and create a New application then go on the application sub-menu Topology . You are now ready to compose you application. Let’s do it ! Step 1 : The Compute In this step, drag and drop a Compute into the topology design view. You need to specify two properties for this compute : os_arch : x86_64 os_type : linux Step 2 : The BlockStorage Now, drag and drop a BlockStorage into the view. Select it by click and then attach it the Compute in the right Properties tab. Make sure to select the relation attachment with 1..1 constraint. In these properties tab view, set also the size value to 1 (GB by default). Step 3 : Apache, MySQL, PHP Then, drag and drop a MySQL , a PHP and an Apache onto the Compute existing node. For each new node droped onto Compute you will have to decide a target for the HostedOn relationship (generally just check the relationship name and click Finish ). Change the default value of MySQL or Apache if you want a custom install. Step 4 : The Wordpress The last component to add is the Wordpress . Drag and drop it to the Apache and select the WordpressHostedOn relationship between Wordpress and Apache . After this, create the relationship between Wordpress and MySQL and between Wordpress and PHP . Deployment Now we can deploy our topology into the cloud we’ve defined in prerequisite. The Deploy button is accessible in the Application sub-menu Deployments . To configure your Wordpress at your first run, open your web browser and go to IP_SERVER/CONTEXT_PATH . To configure your Wordpress , specifically for the MySQL settings, be sure you enter the settings you defined in your MySQL configuration. To check you running application, go on application Runtime sub-menu an select the node you want. In the Details tab automatically selected, you just need to select the instance line you want to have more details like ip_address and public_ip_address an try you application. Here we can select the Compute node and get the public IP to run Wordpress for the first time and later. "},{"title":"Component BlockStorage","baseurl":"","url":"/documentation/getting_started/lamp_stack_blockstorage.html","date":null,"categories":[],"body":"This component represents a storage space / volume. This volume has to be attached to a compute to be used. For more details about this custom component : BlockStorage Used version for this tutorial (defined in normative types): BlockStorage Definition Namming / description Every component should at least inherite from tosca.nodes.Root . As a default normative type it’s the case for BlockStorage . Properties Check details : BlockStorage For the application you will need volume_id or size to be defined. Lifecycle and related scripts There is no lifecycle operation for this component in the default version. "},{"title":"Component MySQL","baseurl":"","url":"/documentation/getting_started/lamp_stack_mysql.html","date":null,"categories":[],"body":"This component will install the MySQL RDBMS on the host server. Used version for this tutorial : MySQL This installation is based on Ubuntu distribution with apt-get command. Definition Let’s describe important parts of this full MySQL definition description. Namming / description The node name is important since it’s unique. We follow this template in A4C recipe development : [organisation].nodes.Name tosca_simple_yaml_1_0_0_wd03 : version of tosca used in the definition, let it as is it for the moment Our node name / id : alien.nodes.Mysql The parent : tosca.nodes.Database It’s a good practice to inherit from a base type to create your own component when it’s possible. Here tosca.nodes.Database . Properties All properties required or optional to use the component. MySQL proper properties : Property Usage Comment port port number injected in the MySQL installation Default : 3306 storage_path path where the blockstorage is mounted in the compute Constant value with the Cloudify Driver version we use in this tutorial. All blockstorage attached to a compute will have this mounted volume. bind_address Allow remote access to your server Default : true Properties inherited from its parent : tosca.nodes.Database Here we are overriding those properties from parent component and we describe a database with a user we want to create at initialization. Property Usage Comment db_name Database name we want to create wordpress to match to our final application case db_user Name of the user who will have rights on this database This user will have all privileges on this dedicated database db_password Password for this user … Lifecycle and related scripts The real script you will run during you different component life steps. Two main steps here in operations bloc : Operation Usage Comment create Executed script to install MySQL on the server Through apt-get on you ubuntu image start Executed script to configure MySQL to use a specific storage path (the blockstorage) Configured and started with specific ubuntu hints (rights concerns) start_detection Detects if Mysql is started Test the port "},{"title":"Component PHP","baseurl":"","url":"/documentation/getting_started/lamp_stack_php.html","date":null,"categories":[],"body":"This component will install the PHP on the host server. Used version for this tutorial : PHP Definition PHP is the programming language of the LAMP stack, it’s a server-side scripting. On this page, we just explain the recipe of this component. Below, the header of the php-type : Properties The PHP recipe is not so complicated, it has only three properties. The first property is the version, like for Apache recipe, it’s just to be mentioned. The two other properties are booleans to install the PHP Apache 2 module or the PHP MySQL module. Property Usage Comment version Mention the php version Constant version in our example (v5) Lifecycle and related scripts PHP inherite from the tosca base type tosca.nodes.SoftwareComponent Operation Usage Comment create Executed script to install PHP on the Compute Through apt-get on ubuntu image "},{"title":"Component Wordpress","baseurl":"","url":"/documentation/getting_started/lamp_stack_wordpress.html","date":null,"categories":[],"body":"Definition The Wordpress is a special component of our LAMP stack. This component will allow to take the last zip of Wordpress to be uploaded on the Apache HTTP Server to be deployed. Used version for this tutorial : Wordpress Properties Wordpress properties : Property Usage Comment context_path Name of folder into the default folder of apache2 Empty as default zip_url URL from where you download the application zip Default : https://wordpress.org/latest.zip Relationship and related scripts Relationship Usage Comment WordpressHostedOnApache Use to describe that the Wordpress is deployed on the targeted Apache server Through apt-get and unzip WordpressConnectToMysql Use to describe the connection between Wordpress and Mysql Set the conf of Mysql into config files of Wordpress WordpressConnectToPHP Use to describe the connection between Wordpress and PHP Install the PHP module for Apache2 To used Wordpress you need to upload the required recipes : Apache2 , Mysql and PHP . When you define a topology, make sure to select a WordpressHostedOn relation between Wordpress and Apache . "},{"title":"LDAP integration","baseurl":"","url":"/documentation/admin/ldap.html","date":null,"categories":[],"body":"Alien 4 Cloud can interface with an external LDAP server in order to retrieve users and perform authentication. When using an LDAP server, the Alien admin can still manage ‘local’ users inside Alien while LDAP users should be managed inside the LDAP repository. It is possible also to delegate global rôle management inside Alien even for LDAP users or to define a mapping from roles inside LDAP to roles within Alien. LDAP configuration In order to plug-in ALIEN to your LDAP repository, you must configure the ldap section of the alien4cloud-config.yml file. Enable LDAP Enabling ldap is as easy as updating the ldap configuration section and changing the enabled flag to true. ### Ldap Configuration ldap : enabled : true ... ### End Ldap Configuration Configure LDAP Server The first step in order to configure LDAP in Alien 4 Cloud is to configure the server parameters: Keynames Keyname Required Description anonymousReadOnly yes Some LDAP server setups allow anonymous read-only access. If you want to use anonymous Contexts for read-only operations, set the anonymousReadOnly property to true. url yes Url of the ldap server. userDn yes Dn of the user to use in order to connect to the LDAP server. password yes Password of the user to use in order to connect to the LDAP server. Example ldap : ... anonymousReadOnly : true url : ldap://ldap.fastconnect.fr:389 userDn : uid=admin,ou=system password : secret ... Configure users retrieval In order to retrieve users from the LDAP you must specify the base in which to look for users as well as an optional filter to retrieve only the users entries (and filter inactive if you have some for example). Keynames Keyname Required Description base yes The base in which to look for users within your LDAP filter yes A filter query to be processed by your LDAP server to filter users retrieved into Alien 4 Cloud. Example ldap : ... base : ou=People,dc=fastconnect,dc=fr filter : (&(objectClass=person)(!(objectClass=CalendarResource))(accountStatus=active)) ... Configure user mapping Now that you can retrieve users from LDAP it is critical to define a Mapping from your LDAP user entry attributes to Alien 4 Cloud properties for a user. Keynames Keyname Required Description mapping:   id: yes Name of the LDAP attribute that contains the unique id for the user within ldap that should be used as user’s login (username) within Alien 4 Cloud. mapping:   firstname: yes Name of the LDAP attribute that contains the user’s firstname mapping:   lastname: yes Name of the LDAP attribute that contains the user’s lastname mapping:   email: yes Name of the LDAP attribute that contains the user’s email mapping:   active:     key: no Name of the LDAP attribute that allows to know if a user is active. mapping:   active:     value: no Value of the LDAP attribute for which the user is considered as active. mapping:   roles:     defaults: yes Roles to use when importing a user when no rôle mapping is defined. Note: this roles are used only on user import. When no role mapping is defined the rôles of users can be managed in Alien4Cloud. mapping:   roles:     key: no Name of the LDAP attribute that contains the user’s rôles. If this key is not specified, user rôles will be managed inside alien. Note: at import users will be created inside alien with the default roles. mapping:   roles:     key: no Mapping of a LDAP rôle to an ALIEN rôle. Note that it is not currently possible to map a single LDAP rôle to multiple Alien rôles. ### Ldap Configuration ldap : ... mapping : id : uid firstname : givenName lastname : sn email : mail # optional mapping key and value to dertermine if the user is active active : key : accountStatus value : active roles : defaults : COMPONENTS_BROWSER # optional configuration for role mapping (when you want to manage roles in ldap and not in alien for ldap users). #key: description #mapping: ROLE_CLOUDADMINS=ADMIN,ROLE_CLOUDCOMPONENTS=COMPONENTS_MANAGER ### End Ldap Configuration Limitations and known issues Even when a user has rôles managed in LDAP an Alien admin can edit it’s rôles. However when the user will log-in the rôles from LDAP will be reloaded into alien. Roles changed in LDAP will not appear in Alien as long as the User doesn’t log-in. "},{"title":"Lifecycles specifics for Cloudify","baseurl":"","url":"/documentation/cloudify2_driver/lifecycle_spec.html","date":null,"categories":[],"body":"There are some specifics concerning some lifecycle events when developing a Cloudify recipe for the ALIEN driver. Supported lifecycles events This provider does not yet support the implementation of all of the Cloudify livecycle events, but it is constantly evolving. The events supported are: Archive Interface operation Standard install (as create ), start , stop fastconnect.cloudify.extensions startDetection (as start_detection ), StopDetection (as stop_detection ), locator Note that the driver only supports groovy scripts for the fastconnect.cloudify.extensions interface’s operations. Also, you must be aware that the routine will be executed as a goovy closure. Therefore, you MUST NOT use the ServiceContextFactory class to get the service context, it has been injected automatically so that you can directly use it via the variable context . Example: interfaces : [ ... ] fastconnect.cloudify.extensions : start_detection : scripts/tomcat_startDetection.groovy stop_detection : scripts/tomcat_stopDetection.groovy locator : scripts/alien_tomcat_locator.groovy startDetection You can provide a start detection routine, and it should be written in a groovy file, and must return a boolean: True if the routine ended well, and false if not. The routine will be executed as a Cloudify closure, in the service descriptor file. Therefore, as stated in the Cloudify documentation, you shouldn’t use the ServiceContextFactory class to get the service context. The context has been injected automatically so that you can directly use it via the variable context . Example: def config = new ConfigSlurper (). parse ( new File ( \"${context.serviceDirectory}/scripts/tomcat-service.properties\" ). toURL ()) def result = ServiceUtils . arePortsOccupied ([ config . port , config . ajpPort ]) return result stopDetection Similar to the case of start detection, written in a groovy file, the stopDetection routine will be executed as a closure must and return a boolean value. Example: def config = new ConfigSlurper (). parse ( new File ( \"${context.serviceDirectory}/scripts/tomcat-service.properties\" ). toURL ()) def result = ServiceUtils . arePortsFree ([ config . port , config . ajpPort ]) return result Locators The locator allows you to specify the proccesses that Cloudify should monitor to determine if the application is stopped, and therefore perform some actions for the failover. Written in a groovy file, the locator will be executed as a closure, and must return a list of processes Pids to monitor. Example: import org.cloudifysource.dsl.utils.ServiceUtils def myPids = ServiceUtils . ProcessUtils . getPidsWithQuery ( \"State.Name.eq=java,Args.*.eq=org.apache.catalina.startup.Bootstrap\" ) return myPids "},{"title":"Node type","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/node_type.html","date":null,"categories":[],"body":"A Node Type is a reusable entity that defines the type of one or more Node Templates. As such, a Node Type defines the structure of observable properties via a Properties Definition, the Requirements and Capabilities of the node as well as its supported interfaces. Keynames Keyname Type Required Description abstract* boolean no Optional flag to specify if a component is abstract and has no valid implementation. Defaults to false.  derived_from string no* An optional parent Relationship Type name the Relationship Type derives from. description string no An optional description for the Relationship Type. properties property definitions no An optional list of property definitions for the Relationship Type. attributes attribute definitions no An optional list of attribute definitions for the Relationship Type. requirements requirement definitions no An optional sequenced list of requirement definitions for the Node Type. capabilities capability definitions no An optional list of capability definitions for the Node Type. artifacts artifact definitions no An optional sequenced list of named artifact definitions for the Node Type. interfaces interface definitions no An optional list of named interfaces for the Relationship Type. Abstract flag is specific to Alien 4 Cloud and is not part of TOSCA Simple Profile in YAML. derived_from is not required however node types SHOULD all extends from a normative type (tosca.nodes.Root, tosca.nodes.SoftwareComponent etc.). Grammar <node_type_name> : derived_from : <parent_node_type_name> description : <node_type_description> properties : <property_definitions> attributes : <attribute_definitions> requirements : - <requirement_definition_1> ... - <requirement_definition_n> capabilities : <capability_definitions> interfaces : <interface_definitions> artifacts : <artifact_definitions> See: property_definitions attribute definitions requirement definitions capability definitions artifact definitions interface definitions Example my_company.my_types.my_app_node_type : derived_from : tosca.nodes.SoftwareComponent description : My company’s custom applicaton properties : my_app_password : type : string description : application password constraints : - min_length : 6 - max_length : 10 my_app_port : type : number description : application port number requirements : - host : tosca.nodes.Compute interfaces : [ Standard ] "},{"title":"Operation definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/operation_definition.html","date":null,"categories":[],"body":"An operation definition defines a named function or procedure that can be bound to an implementation artifact (e.g., a script). Keynames Keyname Type Required Description description string no The optional description string for the associated named operation. implementation string no The optional implementation artifact name (e.g., a script file name within a TOSCA CSAR file). inputs string no The optional list of input parameter definitions. Grammar <operation_name> : description : <operation_description> implementation : <implementation_artifact_name> inputs : <parameter_definition> In addition, the following simplified grammar may also be used (where a full definition is not necessary): <operation_name> : <implementation_artifact_name> implementation_artifact_name must be the path to a file and is resolved starting from the archive root. The artifact must be related to an artifact type. The way artifacts are related to artifact types is based on the implementation artifact name extension. This refers directly to the artifact types file_ext property that may have been defined. If no artifact type matches the extension Alien 4 Cloud will not allow parsing of the artifact. Example The following example shows how to define a node type with operation: node_types : fastconnect.nodes.OperationSample : interfaces : Standard : create : /scripts/install.sh configure : description : This is the configuration description. implementation : /scripts/setup.sh inputs : value_input : 4 "},{"title":"Other specifics interfaces","baseurl":"","url":"/documentation/cloudify2_driver/other_interfaces.html","date":null,"categories":[],"body":"Here are informations concerning some specific interfaces. custom interface Note that the driver only supports groovy scripts for this interface’s operations. Also, you must be aware that the routine will be executed as a goovy closure. Therefore, you MUST NOT use the ServiceContextFactory class to get the service context, it has been injected automatically so that you can directly use it via the variable context . Cloudify allows user to interact with their deployment via custom commands. This interface is design to support custom commands, in form of operations. Example: alien.nodes.cloudify.Tomcar [...] interfaces : [ ... ] custom : updateWarOnTomcat : inputs : catalinaBase : { get_attribute : [ SELF , catalinaBase ] } installDir : { get_attribute : [ SELF , installDir ] } url : type : string required : true contextPath : type : string required : true implementation : scripts/updateWarOnTomcat.groovy alien.nodes.cloudify.War [ ... ] interfaces : [ ... ] custom : updateWarFile : inputs : contextPath : { get_property : [ SELF , contextPath ] } warUrl : type : string description : url of the war to upload to update the current one required : true implementation : warScripts/updateWarFile.groovy Example of custom command scripts: alien.nodes.cloudify.War updateWarFile: assert warUrl && ! warUrl . trim (). isEmpty (), \"requires warUrl parameter\" //when invoking a command defined in another node, prefix it with his name. Here, War is hosted on Tomcat, thus the HOST env var has the Tomcat node name. def command = \"${HOST}_updateWarOnTomcat\" println \"updateWarFile.groovy: warUrl is ${warUrl} and contextPath is ${contextPath}...\" println \"updateWarFile.groovy: invoking ${command} custom command ...\" //SERVICE_NAME env var represent the cloudify service name def service = context . waitForService ( SERVICE_NAME , 60 , TimeUnit . SECONDS ) def currentInstance = service . getInstances (). find { it . instanceId == context . instanceId } //as the inputs are no more accessible via args[], but rather named and available in the env var, we should trigger the custom command with a \"name=value\" instead of \"value\" argument syntax currentInstance . invoke ( command , \"url=${warUrl}\" as String , \"contextPath=${contextPath}\" as String ) return \"war updated.\" "},{"title":"Parameter definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/parameter_definition.html","date":null,"categories":[],"body":"A parameter definition is map used to declare a name for a parameter along with its value to be used as inputs for operations. This value can either be a fixed value or one that is evaluated from a function or expression. Alien 4 Cloud allow users to specify also a property definition as the parameter value. This is possible only for operations that are not part of the automatic lifecycle but that will be triggered upon user request. Grammar <parameter_name> : <value> | <function_definition> See function_definition . For Alien 4 Cloud property definition syntax support you can refer to the property_definition page . Example node_types : fastconnect.nodes.PropertiesSample : interfaces : custom : do_something : inputs : value_input : 4 function_input : { get_property : [ my_host , mem_size ] } property_input : type : string description : An input that will have to be provided on operation call. constraints : - min_length : 4 - max_length : 8 "},{"title":"Previous versions","baseurl":"","url":"/roadmap/past.html","date":null,"categories":[],"body":" You will find here details on previous releases. November 2014, Milestone 3, In progress Tosca Simple Profile wd03 Cloud resources configuration & pluggable matching Network support Block Storage improvements - handling Compute scaling policies properly September 2014, Milestone 2, Done Tosca Simple Profile wd02 HA & Manual scalability Users & Roles management Multi-cloud & tenants support Block Storage support June 2014, Milestone 1, Done Tosca Simple Profile wd01 Middleware & infrastructure component repository Topology designer for graphical composition of a TOSCA blueprint Compute support Cloudify 2 driver - allowing to compose and deploy Blueprints on any Cloud supported by Cloudify v2 . If needed new Cloud drivers can be easily developed "},{"title":"PaaS provider plugins","baseurl":"","url":"/developer_guide/plugin-paas-provider.html","date":null,"categories":[],"body":"ALIEN is not responsible for actual deployments of the defined topologies. It delegates the deployment and orchestration of topologies to PaaS providers. A PaaS provider plugin is responsible for translation of ALIEN’s topology to a topology/blueprint/recipe that can be understood by the actual orchestration tool that it aims to support and to manage deployments/undeployments and monitoring connectivity to ALIEN. "},{"title":"ALIEN plugins","baseurl":"","url":"/developer_guide/plugin.html","date":null,"categories":[],"body":"An ALIEN plugin is a zip archive that contains the following structure: Directory hierarchy An ALIEN plugin is an archive (zip) that must contains the following hierarchy: The root folder contains java classes and resources (basically it will be added to the classpath of the plugin). The lib folder (optional) must contain all java archives (jar) required for the plugin to run. They will be added to the plugin classloader. Of course you should not add ALIEN 4 cloud jars here as they will be loaded through the plugin parent classloader. Finally the META-INF/plugin.yml contains the plugin description and entry point informations (the plugin descriptor). Example of a plugin content. The plugin descriptor The plugin descriptor is mandatory and is the entry point of the plugin for ALIEN. As many other configuration elements it is a YAML file that allows to describe your plugin. grammar As detailed in the architecture section, a ALIEN plugin is actually a Spring sub-context; As so it requires a Spring context configuration entry point. For ALIEN plugins we have decided to allow only java based configuration and thus a plugin must specify a configuration class in it’s descriptor. The configuration class is the only mandatory class in a plugin so it can be loaded by ALIEN. example Plugin context entry point As described higher, a plugin in ALIEN is a spring context that inherits from ALIEN context. This allows you to build plugin that have full access to the repository or any other component in ALIEN. When loading a plugin, ALIEN for cloud will create the spring context based on the spring java configuration class defined in the plugin descriptor. It will then lookup the spring context for plugin beans matching one of a supported plugin type (like a bean that implements IPaaSProvider for example). Below is an example of a plugin spring context java configuration that acts as an entry point for the cloudify plugin. @Configuration @ComponentScan ( \"alien.paas.cloudify\" ) @ImportResource ( \"classpath:properties-config.xml\" ) public class PluginContextConfiguration { } Plugin configuration ALIEN provides an easy way to configure a plugin by generating the UI based on a configuration object using introspection. It also manages persistency of the configuration. In order to enable plugin configuration, one of the bean in your spring context must implements the IPluginConfigurator interface. This interface (see signature below) allow to provide a POJO that will act as the configuration object for the whole plugin. /** Interface for plugin configuration objects. */ public interface IPluginConfigurator < T > { /** * Get an instance of T that is the default configuration object of the plugin. * * @return A configuration object of type T. */ T getDefaultConfiguration (); /** * Set / apply a configuration for a plugin. * * @param configuration The configuration object as edited by the user. */ void setConfiguration ( T configuration ); } Current version of ALIEN 4 Cloud does not supports more than a single configuration. Thus you should make sure that a single IPluginConfigurator exists in your plugin spring context. "},{"title":"Plugins Management","baseurl":"","url":"/admin_guide/plugins.html","date":null,"categories":[],"body":"This section details Alien 4 Cloud’s Plugins management. For more information about what is a plugin, please see ALIEN plugins How to navigate to Plugins Management view Log in with admin credentials > Click on your user’s name on the right top corner > Click on drop-down link Plugins . You’ll arrive to the plugins management view, for the moment the page is empty as you haven’t uploaded any plugin yet. Empty plugins management view Upload a new plugin Drag plugin archive into the below dash dotted area. For browser which does not support drag & drop feature, you’ll see a button instead to choose the archive to upload. Once plugin uploaded, you’ll be able to see it in the browser. Plugins list Id : unique identifier of the plugin Version : version of the plugin Name : name of the plugin Description : the plugin’s description Enabled : indicate if the plugin is available for deployment Plugin managements Actions available to manage plugins can be found in the button group on the right hand side : delete, disable, configure. When you hover the mouse cursor on these buttons you’ll have tooltips explaining their functionality. Delete Click on the button below to delete the plugin. All related resources to the plugin will be cleaned up. Disable Click on the button below to disable a plugin. The plugin resource will not be cleaned up, this action will just make the plugin unavailable for deployment, you can always re-enable the plugin later. Click again on the button to enable the plugin. Configure Click on the button below to open configuration modal dialog. You can begin to edit the plugin configuration Plugin configure action This view is specific to each plugin, the above image is just a mock. For more information on how to configure your plugin, please refer to the specific section concerning your plugin. "},{"title":"Prerequisites","baseurl":"","url":"/documentation/cloudify2_driver/prerequisites.html","date":null,"categories":[],"body":"Here are listed the prerequisites to satisfy before using this driver. Related Topics "},{"title":"Property definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/property_definition.html","date":null,"categories":[],"body":"A property definition defines a named, typed value that can be associated with an entity defined in this specification. It is used to associate a transparent property or characteristic of that entity which can either be set (configured) on or retrieved from it. Keynames Keyname Type Required Description type string yes The required data type for the property. description string no The optional description for the property. required boolean no (default true) Optional key to define if the property is requied (true) or not (false). If this key is not declared for the property definition, then the property SHALL be considered required by default. default N/A no An optional key that may provide a value to be used as a default if not provided by another means. This value SHALL be type compatible with the type declared by the property definition’s type keyname. constraints list of constraints no The optional list of sequenced constraints for the property. Grammar <property_name> : type : <property_type> description : <property_description> required : <property_required> default : <property_default_value> constraints : - <property_constraint_1> - ... - <property_constraint_n> See: constraints Example The following example shows how to define a node type with properties: node_types : fastconnect.nodes.PropertiesSample : properties : property_1 : type : string property_2 : type : string required : false default : This is the default value of the property description : this is the second property of the node constraints : - min_length : 4 - max_length : 8 property_3 : type : integer default : 45 "},{"title":"Relationship type","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/relationship_type.html","date":null,"categories":[],"body":"A Relationship Type is a reusable entity that defines the type of one or more relationships between Node Types or Node Templates. Keynames Keyname Type Required Description abstract* boolean no Optional flag to specify if a component is abstract and has no valid implementation. Defaults to false.  derived_from string no* An optional parent Relationship Type name the Relationship Type derives from. description string no An optional description for the Relationship Type. properties property definitions no An optional list of property definitions for the Relationship Type. attributes attribute definitions no An optional list of attribute definitions for the Relationship Type. interfaces interface definitions no An optional list of named interfaces for the Relationship Type. valid_sources string[] no An optional list of one or more valid target entities or entity types (i.e., a Node Types or Capability Types). valid_targets string[] yes A required list of one or more valid target entities or entity types (i.e., a Node Types or Capability Types). Abstract flag is specific to Alien 4 Cloud and is not part of TOSCA Simple Profile in YAML. derived_from is not required however relationship types SHOULD all extends from a normative type (ConnectsTo or HostedOn for example). Grammar <relationship_type_name> : derived_from : <parent_relationship_type_name> description : <relationship_description> properties : <property_definitions> attributes : <attribute_definitions> interfaces : <interface_definitions> valid_targets : [ <entity_name_or_type_1> , ... , <entity_name_or_type_n> ] See: property_definitions attribute definitions interface definitions Example mycompanytypes.myrelationships.AppDependency : derived_from : tosca.relationships.DependsOn valid_targets : [ mycompanytypes.mycapabilities.SomeAppCapability ] "},{"title":"Requirement definition","baseurl":"","url":"/documentation/tosca_ref/tosca_grammar/requirement_definition.html","date":null,"categories":[],"body":"A requirement definition allows specification of a requirement that a node need to fulfill to be instanciated. Keynames Keyname Type Required Description type (Alien 4 Cloud supports also relationship_type) string no The optional reserved keyname used to provide a named Relationship Type to use when fulfilling the associated named requirement. lower_bound integer no Lower boundary by which a requirement MUST be matched. Valid values are any positive number, 0 meaning that the requirement is optional. Defaults to 1. upper_bound integer (or unbounded string) no Upper boundary by which a requirement MUST be matched for Node Templates. Valid values are any positive number or unbounded string that means that there is no upper limit. Defaults to 1. Grammar # using type <requirement_name> : <capability_type or node_type> type : <relationship_type> lower_bound : <lower_bound> upper_bound : <upper_bound> # alien 4 cloud specific support more meaningful <requirement_name> : <capability_type or node_type> relationship_type : <relationship_type> lower_bound : <lower_bound> upper_bound : <upper_bound> Example node_types : fastconnect.nodes.RequirementSample : requirements : - host : tosca.nodes.Compute relationship_type : tosca.relationships.HostedOn lower_bound : 0 upper_bound : unbounded "},{"title":"Roles in Alien 4 Cloud","baseurl":"","url":"/documentation/getting_started/roles.html","date":null,"categories":[],"body":"This section details Alien 4 Cloud’s ROLES and permissions by role. General Alien 4 Cloud roles These roles describes global roles you can grant to a user. From his/her roles Alien 4 Cloud will display and allow some operations. Role Description ADMIN Manages users, plugins, configure clouds + all other roles. APPLICATIONS_MANAGER Create new application(s). ARCHITECT Create and edit topology template(s). COMPONENTS_BROWSER [Deprecated] Not used anymore for validation. Can list components and see details for any of them COMPONENTS_MANAGER Manage TOSCA cloud service archives to add/remove components from the catalog. A user with no roles can log-in and view the resources for which he has been granted. For example a user with no global roles can still access and manage applications on which he has resources roles (see application and environments roles). Application’s roles These roles defines actions allowed by role on a given application : Role Description APPLICATION_MANAGER Application manager can manage the application configuration, it’s versions and environments as well as user management for the application. APPLICATION_DEVOPS Dev ops role should be given to the applications developer. In ALIEN users with devops role on an application can edit the topologies of every SNAPSHOT versions. In addition to the applications roles, Application manager can specify some roles related to every single environment defined for the application. Environment’s roles These roles defines actions allowed by role on a given environment : Role Description APPLICATION_USER An application user on an environment is allowed to see the environment status as well as having access to the deployment output properties (URL for example so he can directly reach the deployed application). DEPLOYMENT_MANAGER Deployment manager for an environment is responsible for configuration and deployment/undeployment of an environment. In order to be able to deploy/undeply the environment the user must also have a CLOUD_DEPLOYER role on the cloud that is associated with the environment. CLOUD_DEPLOYER role is configured on the cloud configuration by any user having the global ADMIN role. "},{"title":"Testing custom components","baseurl":"","url":"/documentation/getting_started/snapshot_topology_test.html","date":null,"categories":[],"body":"ALIEN rest api provides methods to test your topology during development. In fact you can package a CSAR file with a topology test and then run the deployment test on this archive. Prerequisites Prepare your archive You need first to correctly create your archive (more details about archive here ) Just add a specific test folder to this archive to have a tree as follow ├── Definitions │   ├── java-types.yaml │   └── tosca-base-types.yaml ├── images │   ├── compute.png │   └── ... ├── test │   └── sample-application.yaml └── TOSCA-Metadata └── ALIEN-META.yaml This test folder should contain at least one yaml file topology description Only the first found yaml file is tested In your topology written in yaml format, you can use components already integrated in ALIEN or put yours in the snapshot archive Like for other CSAR file, yaml files under Definitions folder will be loaded into ALIEN at archive upload For example, in this demo archive we bring our own java-types and tosca-base-types components (self-sufficient archive) Archive naming Another important file in this test archive is the ALIEN-META.yaml . In fact in this file you have 2 informations used to run the topology deployment test : name version name : \"topology-test\" version : \"2.0-SNAPSHOT\" license : \"Apache v2.0\" created_by : \"FastConnect\" ... Only SNAPSHOT archive version can be used to run test. We suppose that in “development mode” we only handle snapshot version which we can override at anytime and then run other test. How to test your topology For this section we’ll use our “hello world” topology archive test : hello-world-topology.zip This archive contains a yaml file corresponding to the following topology in test directory : You need first an actived cloud A “cloud” is based on a plugin (driver), so first upload your plugin jar with the ADMIN role Then you will have the following plugin administration page where you can create a cloud and activate it From the cloud details page you want to target, you have to get the cloud id Upload your snapshot archive Just upload your snapshot archive in the components view After the upload you’ll see all components contained in the snapshot archive listed in the components view Run rest command to test Get any REST client or just go on the api document http://localhost:8080/ api-doc/index.html from where you can send request Look for cloud-service-archive-controller and the operation : You need 3 parameters to run the test : csarId , csarVersion , cloudId (id recovered from cloud details page) Final request example : http://localhost:8080/rest/csars/ topology-test /version/ 2.0-SNAPSHOT /cloudid/ 7ede236c-0456-478b-b68c-502474c45987 Test the result From the step 3 you’ll obtain a deployment id only if your deployment test is successful (UUID form, e.g : 391e5d07-e2b0-44ea-bf87-81cdc080a9e1) Errors from the deployment are not really “meaningful” in the version (to improve) You have 2 other services you must use during your topology test process in deployment-controller You can recover the status from your deployment id, the same way you’ve launched the test in step 3 Example : http://localhost:8080/rest/deployments/ 391e5d07-e2b0-44ea-bf87-81cdc080a9e1 /status Possible results : ‘DEPLOYED’ or ‘UNDEPLOYED’ or ‘DEPLOYMENT_IN_PROGRESS’ or ‘UNDEPLOYMENT_IN_PROGRESS’ or ‘WARNING’ or ‘FAILURE’ or ‘UNKNOWN’ The status should be at state DEPLOYED for a correct deployment To finish we advice you to clean your deployment “stack” manually with the undeploy request Example : http://localhost:8080/rest/deployments/ 391e5d07-e2b0-44ea-bf87-81cdc080a9e1 /undeploy Undeployment success : no result You might have different states of your deployment regarding the moment you launch the status request. "},{"title":"Tests with jenkins plugin","baseurl":"","url":"/documentation/getting_started/snapshot_topology_test_jenkins_plugin.html","date":null,"categories":[],"body":"We have seen here that we can use the ALIEN REST API to archive tests. Based on it, a jenkins plugin has been developed (and still being improved) to automate all the test routine. The plugin is written in JAVA language, and can ca lunch a serie of BDD (Behaviour Driven Development) tests with the help of Cucumber framework. The tests are lunched via configurables Jenkins “FreeStyle” jobs. You can then configure the ALIEN instance on which to perform tests, the cloud, the credential to be used, and also specify whether or not to undeploy the test application before endind the job. Prerequisites Prepare your archive Follow the same instructions as the ones explained here . in addition, add in the “ test ” folder your cucumbr file (a .feature file). Your archive should look like: ├── Definitions │   ├── java-types.yaml │   └── tosca-base-types.yaml ├── images │   ├── compute.png │   └── ... ├── test │   ├── sample-application.yaml └── tests.feature └── TOSCA-Metadata └── ALIEN-META.yaml The cucumber (.feature) file In this file, you will have to describe what you whant to test and the way the tests should be proceeded. Currently, we only support a few steps: Feature: Install Tomcat application and test status Scenario: I install an application Given a cloud \" cloud \" created When i deploy the test application Then i have application \" deployed \" within 10000 milliseconds Package and Install the plugin Fist you need to clone the repository and package the plugin to have a .hpi file. Then install the plugin in your running instance of Jenkins. (For more information, see the Readme file in the plugin repository). How to test your topology Archive and location After preparing the archive, you have to put it at jenkins disposal. For now the solution is to upload the folder content (unzipped) on a git or svn. For the next steps, you should make sure you have a running instance of Alien 4 Cloud (copy its URL), and a cloud created and activated (note its name) Jenkins job First you must create a “FreeStyle” job on jenkins. Configure the job. In the “ Source Code Management ” section, select your provider and fill in the repository URL where you’ve uploded the content of your archive. Next, configure the build environment, by checking the option Setup Alien4Cloud test environment. This will set up some variables for the tests. Also optionnaly check the sub-option if you want the job to automatically undeploy the test application at the end. Add a build step. From the lists, Select “ALIEN 4 Cloud arhives tests”. And configure the parameters. Note that some of them might be required for the job to run well. You can now save the job config, and run it. Check for the job output to see how tests are going. If you didn’t check the option to automatically undeploy the application at the end, you might have to do it manually. Thus, you need the deployment Id, which you can find checking the job logs. Actually, we only support deployment and checking of it status. More steps will be added later. "},{"title":"Storage volumes","baseurl":"","url":"/documentation/cloudify2_driver/storage.html","date":null,"categories":[],"body":"The Alien4Cloud cloudify 2.X provider supports TOSCA Blockstorage feature. Find here usefull information about how to implement it and how the provider handles it. Related Topics "},{"title":"TOSCA archive","baseurl":"","url":"/documentation/cloudify2_driver/tosca_archive.html","date":null,"categories":[],"body":"Here are informations about how to adapt your TOSCA archives. You might first want to go check about TOSCA guide before continuing, as we assume here that you are familiar with those concepts. Related Topics "},{"title":"TOSCA definitions","baseurl":"","url":"/documentation/cloudify2_driver/tosca_archive_definitions.html","date":null,"categories":[],"body":"The Cloudify driver for ALEIN 4 CLOUD allows you to deploy applications on several clouds, using Cloudify 2.7. Thus you have to design TOSCA archives containing nodes , and upload them in your ALIEN instance. If your archive contains deployable nodes, you might have to add to their definitions some artifacts and interfaces. Standard interface As its name states, the Standard interface allows you to define some lifecycle events for your node. Both Cloudify and TOSCA have this iterface in their specifications, with diferent operations names. Yet, it is possible to make a mapping from TOSCA to Cloudify lifecycle. Operations TOSCA Cloudify Supported Description create install YES  Allows to define the way to create / install your node when deploying configure - YES  Specify the routine to run to configure the node start start YES  Allows to define the way to start the node stop stop YES  Specify the routine to run to stop the node delete - NO  Specify the routine to run to cleanup after Example: interfaces : Standard : create : scripts/tomcat_installCalm.groovy start : scripts/tomcat_start.groovy stop : scripts/tomcat_stop.sh The artifact_type s tosca.artifacts.GroovyScript , tosca.artifacts.ShellScript and fastconnect.artifacts.ResourceDirectory are provided by ALIEN in a base package. For the Standard interface, you can use both Groovy and Shell scripts. Your scripts folder The operations implementation’s scripts are automatically copied along with your node on deployment. However, if they are not independant, meaning they rely on, or call other files, you must reference these latest as artifacts. The simplest way is to define an artifact of type tosca.artifacts.File referencing the folder where are stored all of your scripts. artifacts : - scripts : scripts type : tosca.artifacts.File fastconnect.cloudify.extensions interface Aside of the above operations, Cloudify also provides various lifecycle events. All of them are not mappable to a TOSCA Standard event. Therefore, ALIEN defined an interface, fastconnect.cloudify.extensions to help handling some of those operations. The ones currently supported by ALIEN are: StartDetection StopDetection locator Note that the driver only supports groovy scripts for this interface’s operations . See Cloudify specifics about them. "},{"title":"TOSCA concepts","baseurl":"","url":"/documentation/tosca_ref/tosca_concepts.html","date":null,"categories":[],"body":"TOSCA specification allows users to specify a cloud application’s topology by defining a set of nodes that are connected to other using relationships. The goal of the TOSCA specification is to focus on a good meta-definition of cloud applications and their components and focus on the following goals: Reusability of components Interoperability of TOSCA archive through the different TOSCA containers In order to manage reusability of components and defined recipes, TOSCA allows definition of NodeTypes that specify the available components and eventually their implementation (for example a Java NodeType and the script implementation to install it on a virtual server). The defined NodeTypes can then be reused when a developer or application architect want to define the topology of a cloud application. TOSCA Simple Profile in YAML TOSCA Simple profile in YAML allows definition of TOSCA elements in a YAML format rather than XML. The YAML format is simpler to write and offers some shorter ways to defined a TOSCA definition. Note: TOSCA Simple profile is a working draft and is not released yet to public. Current Alien 4 Cloud version is using a Alien 4 Cloud’s specific DSL that is really close to the latest TOSCA Simple Profile in YAML TC work. This may be subject to some updates in the future. TOSCA in Alien 4 Cloud In Alien 4 Cloud, TOSCA can be used to define both Types (catalog elements) and Applications topologies (Templates). Alien 4 Cloud tools like the topology editor allows you to create Application topologies that can be exported to Tosca Templates. Alien 4 Cloud support a slightly modified version of TOSCA Simple Profile in YAML in order to add features that are specific to Alien 4 Cloud context. However we are able to load pure TOSCA compliant templates and also export topologies as pure TOSCA templates. Export feature will be available in the next release. "},{"title":"Writing custom types","baseurl":"","url":"/documentation/tosca_ref/tosca_concepts_types_custom.html","date":null,"categories":[],"body":"TOSCA specification allows definition of a cloud application by defining a set of nodes that are connected to other using relationships. In order to improve reusability of components and defined recipes, TOSCA allow the definition of NodeTypes that defines components and eventually their implementation (for example a Java NodeType and the script implementation to install it on a virtual server). The defined NodeTypes can then be reused when a developer or application architect want to define the topology of a cloud application. TOSCA and thus Alien 4 Cloud allows you to define some abstract types (basically meta-types without implementation). This allows of course to dissociate the specific technical implementations from the actual definition of a component (writing an abstract Java node and several implementations with chef, puppet etc.). This can also be leveraged in order to meta-model your applications for the cloud even if you don’t need to deploy them right now. Alien 4 Cloud advisory features for moving to the cloud leverage this to quiclky map your Information System and get feedback on your application’s cloud maturity and migration advisory. The sub-sections details how you can write your own Capability Types, Node Types and Relationship Types to extends the one that Alien 4 Cloud already provides to you. Definition of Node Types and other elements in TOSCA should be done in a definition file and packaged in a Cloud Service Archive "},{"title":"Normative Types","baseurl":"","url":"/documentation/tosca_ref/normative_types/tosca_concepts_types_normative.html","date":null,"categories":[],"body":"TOSCA Specification defines some basic root types (TOSCA Normative types). There is default types for the Infrastructure and for the appliction. Most of the application components however are not part of normative types but should extends from the TOSCA root types. This allows the container to leverage the default nodes lifecycle in order to automate Plan creation. If you add some custom nodes that doesn’t extends from the Normative types, the container will not be able to include them in an auto-generated plan, every application that uses such types will require a custom defined plan. Even if it is possible to do so this is not recommended. Normative Lifecycle TOSCA Normative types defines the root nodes and default lifecycle to ease writing and using TOSCA for real applications. The default lifecycle can be extended and improved through the creation of custom plans but should fit most usages. "},{"title":"Capabilities","baseurl":"","url":"/documentation/tosca_ref/normative_types/tosca_concepts_types_normative_capabilities.html","date":null,"categories":[],"body":"Normatives capability types in TOSCA tosca.capabilities.Root This is the default (root) TOSCA Capability Type definition that all other TOSCA Capability Types derive from. Definition capability_types : tosca.capabilities.Root : description : > This is the default (root) TOSCA Capability Type definition that all other TOSCA Capability Types derive from. tosca.capabilities.Container The Container capability, when included on a Node Type or Template definition, indicates that the node can act as a container for (or a host for) one or more other declared Node Types. Properties Name Required Type Constraints Description valid_node_types true string[] A list of one or more names of Node Types that are supported as containees that declare the Container type as a Capability.   Definition tosca.capabilities.Container : derived_from : tosca.capabilities.Root properties : valid_node_types : type : string[] required : true description : Array of node types that are valid node types to be contained. description : > A list of one or more names of Node Types that are supported as containees that declare the Container type as a Capability. tosca.capabilities.Endpoint This is the default TOSCA type that should be used or extended to define a network endpoint capability. Properties Name Required Type Constraints Description protocol yes string None The name of the protocol (i.e., the protocol prefix) that the endpoint accepts. Examples: http, https, tcp, udp, etc. port yes integer greater_or_equal:1 less_or_equal:65535 The port of the endpoint. secure no boolean default = false Indicates if the endpoint is a secure endpoint. Definition tosca.capabilities.Endpoint : derived_from : tosca.capabilities.Feature properties : protocol : type : string default : http port : type : integer constraints : - greater_or_equal : 1 - less_or_equal : 65535 secure : type : boolean default : false tosca.capabilities.DatabaseEndpoint This is the default TOSCA type that should be used or extended to define a specialized database endpoint capability. Definition tosca.capabilities.DatabaseEndpoint : derived_from : tosca.capabilities.Endpoint tosca.capabilities.Attachment This is the default TOSCA type that should be used or extended to define a network endpoint capability. Definition tosca.capabilities.Attachment : derived_from : tosca.capabilities.Root "},{"title":"Nodes","baseurl":"","url":"/documentation/tosca_ref/normative_types/tosca_concepts_types_normative_nodes.html","date":null,"categories":[],"body":"The nodes on this page follow the exact TOSCA normative types except the added tags section that we use in ALIEN to specify additional tags on a components. One of them being a specific tag that we use to package the icon that will be used in the UI for a given component. Normatives node types in TOSCA tosca.nodes.Root This is the Root TOSCA Node Type that other nodes extends from. This allows to have a consistent set of features for modeling and management (e.g., consistent definitions for requirements, capabilities and lifecycle interfaces). All Node Type definitions SHOULD extends from the TOSCA Root Node Type. This allows your custom nodes to be included in the default lifecycle generation (based on the root node lifecycle interface). Interfaces The Root node uses the lifecycle interface. See more informations on normative types lifecycle. Definition node_types : tosca.nodes.Root : abstract : true description : > This is the default (root) TOSCA Node Type that all other TOSCA nodes should extends. This allows all TOSCA nodes to have a consistent set of features for modeling and management (e.g, consistent definitions for requirements, capabilities, and lifecycle interfaces). tags : calm_icon : /images/root.png requirements : dependency : type : tosca.capabilities.Root lower_bound : 0 upper_bound : unbounded interfaces : lifecycle : description : Default lifecycle for nodes in TOSCA. operations : create : description : Basic lifecycle create operation. configure : description : Basic lifecycle configure operation. start : description : Basic lifecycle start operation. stop : description : Basic lifecycle stop operation. delete : description : Basic lifecycle delete operation. tosca.nodes.Compute Represents a real or virtual machine or ‘server’. Informations specified on the Compute node will be used to find the machine that fits the given requirements in the cloud available machines. If no sizing informations are specified the cloud’s provider default machine will be used. It is strongly recommended to specify the required cpus and memory at least. Properties Name Required Type Constraints Description num_cpus no integer >= 1 Number of (actual or virtual) CPUs associated with the Compute node. disk_size no integer >=0 Size of the loal disk, in Gigabytes (GB), available to applications running on the Compute node. mem_size no integer >=0 Size of memory, in Megabytes (MB), available to applications running on the Compute node. os_arch yes string none The host Operating System (OS) architecture. Example of valid values includes: x86_32, x86_64, etc. os_type yes string none The hots Operating System (OS) type. Example of valid values includes: linux, windows, aix, macos, etc. os_distribution no string none The host Operating System (OS) distribution. Example of valid values includes: debian, fedora, rhel, and ubuntu os_version no string none  The host Operating System (OS) version. Attributes Name Required Type Description ip_address no string  The primary IP address assigned by the cloud provider that applications may use to access the Compute node. Definition node_types : tosca.nodes.Compute : derived_from : tosca.nodes.Root description : > Represents a real or virtual machine or ‘server’. Informations specified on the Compute node will be used to find the machine that fits the given requirements in the cloud available machines. If no sizing informations are specified the cloud’s provider default machine will be used. It is strongly recommended to specify the required cpus and memory at least. properties : num_cpus : type : integer constraints : - greater_than : 0 description : Number of (actual or virtual) CPUs associated with the Compute node. mem_size : type : integer constraints : - greater_than : 0 description : Size of memory, in Megabytes (MB), available to applications running on the Compute node. disk_size : type : integer constraints : - greater_than : 0 description : Size of the local disk, in Gigabytes (GB), available to applications running on the Compute node. os_arch : type : string required : true constraints : - valid_values : [ \"x86_32\" , \"x86_64\" ] description : The host Operating System (OS) architecture. os_type : type : string required : true constraints : - valid_values : [ \"linux\" , \"aix\" , \"mac os\" , \"windows\" ] description : The host Operating System (OS) type. os_distribution : type : string description : The host Operating System (OS) distribution. os_version : type : string description : The host Operating System version. attributes : ip_address : type : string description : > The primary IP address assigned by the cloud provider that applications may use to access the Compute node. Note: This is used by the platform provider to convey the primary address used to access the compute node. Future working drafts will address implementations that support floating or multiple IP addresses. capabilities : host : type : tosca.capabilities.Container properties : valid_node_types : [ tosca.nodes.SoftwareComponent ] tosca.nodes.BlockStorage The TOSCA BlockStorage node currently represents a server-local block storage device (i.e., not shared) offering evenly sized blocks of data from which raw storage volumes can be created. Properties Name Required Type Constraints Description size no string None The requested storage size in MegaBytes (MB). volume_id no integer >0 ID of an existing volume (that is in the accessible scope of the requesting application). snapshot_id no integer >0 Some identifier that represents an existing snapshot that should be used when creating the block storage (volume). Attributes Name Required Type Constraints Description volume_id no integer >0 ID provided by the orchestrator for newly created volumes. Definition node_types : tosca.nodes.BlockStorage : derived_from : tosca.nodes.Root description : > The TOSCA BlockStorage node currently represents a server-local block storage device (i.e., not shared) offering evenly sized blocks of data from which raw storage volumes can be created. tags : calm_icon : /images/volume.png properties : size : type : integer constraints : - greater_than : 0 description : The requested storage size in MegaBytes (MB). volume_id : type : string description : ID of an existing volume (that is in the accessible scope of the requesting application). snapshot_id : type : string description : Some identifier that represents an existing snapshot that should be used when creating the block storage (volume). attributes : volume_id : type : string description : ID provided by the orchestrator for newly created volumes. requirements : attachment : type : tosca.capabilities.Attachment tosca.nodes.ObjectStorage The TOSCA ObjectStorage node represents storage that provides the ability to store data as objects (or BLOBs of data) without consideration for the underlying filesystem or devices. Properties Name Required Type Constraints Description store_name yes string None The logical name of the object store (or container). store_size no integer >=0 The requested initial storage size in Gigabytes (GB). store_maxsize no integer >=0 The requested maximum storage size in Gigabytes (GB). Definition node_types : tosca.nodes.ObjectStorage : abstract : true derived_from : tosca.nodes.Root description : > The TOSCA ObjectStorage node represents storage that provides the ability to store data as objects (or BLOBs of data) without consideration for the underlying filesystem or devices. tags : calm_icon : /images/objectstore.png properties : store_name : type : string required : true description : The logical name of the object store (or container). store_size : type : integer constraints : - greater_or_equal : 0 description : The requested initial storage size in Gigabytes. store_maxsize : type : integer constraints : - greater_than : 0 description : The requested maximum storage size in Gigabytes. tosca.nodes.SoftwareComponent The TOSCA SoftwareComponent node represents a generic software component that can be managed and run by a TOSCA Compute Node Type. Properties Name Required Type Constraints Description version no version None The software component’s version. Definition node_types : tosca.nodes.SoftwareComponent : abstract : true derived_from : tosca.nodes.Root description : > The TOSCA SoftwareComponent Node Type represents a generic software component that can be managed and run by a TOSCA Compute Node Type. requirements : host : type : tosca.nodes.Compute relationship_type : tosca.relationships.HostedOn tags : calm_icon : /images/software.png tosca.nodes.WebServer The TOSCA WebServer Node Type represents an abstract software component or service that is capable of hosting and providing management operations for one or more WebApplication nodes. Definition node_types : tosca.nodes.WebServer : abstract : true derived_from : tosca.nodes.SoftwareComponent description : > The TOSCA WebServer Node Type represents an abstract software component or service that is capable of hosting and providing management operations for one or more WebApplication nodes capabilities : http_endpoint : type : tosca.capabilities.Endpoint https_endpoint : type : tosca.capabilities.Endpoint host : type : tosca.capabilities.Container properties : valid_node_types : [ tosca.nodes.WebApplication ] tosca.nodes.WebApplication The TOSCA WebApplication node represents a software application that can be managed and run by a TOSCA WebServer node. Specific types of web applications such as Java, etc. could be derived from this type. Definition node_types : tosca.nodes.WebApplication : derived_from : tosca.nodes.Root description : > The TOSCA WebApplication node represents a software application that can be managed and run by a TOSCA WebServer node. Specific types of web applications such as Java, etc. could be derived from this type. requirements : host : type : tosca.nodes.WebServer relationship_type : tosca.relationships.HostedOn tosca.nodes.DBMS The TOSCA DBMS node represents a typical relational, SQL Database Management System software component or service. Properties Name Required Type Constraints Description dbms_port yes integer None The port the DBMS service will listen to for data and requests. dbms_root_password no string None The user account used for the DBMS administration. Definition node_types : tosca.nodes.DBMS : abstract : true derived_from : tosca.nodes.SoftwareComponent description : > The TOSCA DBMS node represents a typical relational, SQL Database Management System software component or service. tags : calm_icon : /images/relational_db.png properties : dbms_root_password : type : string description : the root password for the DBMS service. dbms_port : type : integer description : the port the DBMS service will listen to for data and requests capabilities : host : type : tosca.capabilities.Container properties : valid_node_types : [ tosca.nodes.Database ] tosca.nodes.Database Base type for the schema and content associated with a DBMS. The TOSCA Database node represents a logical database that can be managed and hosted by a TOSCA DBMS node. Properties Name Required Type Constraints Description db_user yes string None The special user account used for database administration. db_password yes string None The password associated with the user account provided in the ‘db_user’ property. db_port yes integer None The port the database service will use to listen for incoming data and requests. db_name yes string None The logical database name. Definition node_types : tosca.nodes.Database : derived_from : tosca.nodes.Root description : > Base type for the schema and content associated with a DBMS. The TOSCA Database node represents a logical database that can be managed and hosted by a TOSCA DBMS node. tags : calm_icon : /images/relational_db.png properties : db_user : type : string required : true description : The special user account used for database administration. db_password : type : string required : true description : The password associated with the user account provided in the ‘db_user’ property. db_name : type : string required : true description : The logical name of the database. "},{"title":"Relationships","baseurl":"","url":"/documentation/tosca_ref/normative_types/tosca_concepts_types_normative_relationships.html","date":null,"categories":[],"body":"Normatives relationship types in TOSCA tosca.relationships.Root This is the default (root) TOSCA Relationship Type definition that all other TOSCA Relationship Types derive from. Definition tosca.relationships.Root : # The TOSCA root relationship type has no property mappings interfaces : tosca.interfaces.relationship.Configure : documentation : > Default lifecycle for nodes in TOSCA. operations : pre_configure_source : documentation : Operation to pre-configure the source endpoint. pre_configure_target : documentation : Operation to pre-configure the target endpoint. post_configure_source : documentation : Operation to post-configure the source endpoint. post_configure_target : documentation : Operation to post-configure the target endpoint. add_target : documentation : Operation to add a target node. remove_target : documentation : Operation to remove a target node. tosca.relationships.DependsOn This type represents a general dependency relationship between two nodes. Depends on impacts the TOSCA default lifecycle. A node that depends from a target node will be started after the target node has been actually started. Definition tosca.relationships.DependsOn : derived_from : tosca.relationships.Root valid_targets : [ tosca.capabilities.Root ] tosca.relationships.HostedOn This type represents a hosting relationship between two nodes. Definition tosca.relationships.HostedOn : derived_from : tosca.relationships.DependsOn valid_targets : [ tosca.capabilities.Container ] tosca.relationships.ConnectsTo This type represents a network connection relationship between two nodes. Definition tosca.relationships.ConnectsTo : derived_from : tosca.relationships.DependsOn valid_targets : [ tosca.capabilities.Endpoint ] tosca.relationships.AttachTo This type represents an attachment relationship between two nodes. For example, an AttachTo relationship type would be used for attaching a storage node to a Compute node. Properties Definition tosca.relationships.AttachTo : derived_from : tosca.relationships.Root valid_targets : [ tosca.capabilities.Attachement ] properties : location : type : string constraints : min_length : 1 device : type : string "},{"title":"Workflows","baseurl":"","url":"/documentation/tosca_ref/tosca_concepts_workflows.html","date":null,"categories":[],"body":"TOSCA Specification defines the notion of Plans . Plans are basically workflows that the tosca container will be able to leverage to administrate the defined tosca application. The specification defines two basic workflow (plans): build : Used to instanciate and start a topology. terminate : Used to tear down a topology. In order to ease TOSCA usage the normative types specification include default lifecycle operations on node types and relationship types that can be used in order to automatically generate workflows (plans). This is why most of users won’t have to define plans. Workflow definition Workflow definition is inspired by BPMN2 but focus on required events, gateways and activities for TOSCA. The following section defines the available elements and the way to define them in a TOSCA Simple profile in YAML. Definition of elements is also adapted to match the TOSCA Simple profile in YAML concepts. Events Start event Every plan should start with the start event, if omitted the container will automatically add it as first element of the workflow. Graphical representation The following symbol represents the start event. Grammar workflows : <flow_id> : <id> : startEvent End event Every plan should finish with the end event, if omitted the container will automatically add it as last element of the workflow. Graphical representation The following symbol represents the end event. Grammar workflows : <flow_id> : <id> : endEvent Update State send message event Update the state of a node template or relationship template. Graphical representation The following symbol represents the end event. target: state Grammar workflows : <flow_id> : # Simple notation <id> : stateUpdate:<target>#<state> # Detailed notation <id> : stateUpdate : target : <target> state : <state> Update State receive message event Receive a state update to trigger next operation. Graphical representation The following symbol represents the end event. target: state Grammar workflows : <flow_id> : # Simple notation <id> : receiveStateUpdate:<target>#<state> # Detailed notation <id> : receiveStateUpdate : target : <target> state : <state> Activities The single activity a TOSCA plan can contains is a specific execute operation Task activity. Execute task Execute allows to execute an operation defined on an entity’s (node or relationship) interface. Graphical representation Grammar workflows : <flow_id> : # Simple notation <id> : execute : <target>#<interface>#<operation> # Detailed notation <id> : execute : target : <target> interface : <interface> operation : <operation> Gateways The only gateways used to define the TOSCA workflows is the parallel gateway. A parallel gateway can be diverging or converging. To ease configuration of the flow the two gateways are considered here a separate elements. Parallel Diverging gateway A parallel diverging gateway allows to specify subflows that will run concurrently. Note that if a task is specified in the flow after a Parallel Diverging Gateway, a Parallel Converging Gateway including all elements from the previous converging gateway is automatically added to the flow. Graphical representation Grammar workflows : <flow_id> : <id> : divergingGateway : <subflow_id_1> : <task_id>... <subflow_id_2> <task_id>... ... <subflow_id_n> <task_id>... Parallel Converging gateway A Parallel Converging gateway allows Graphical representation Grammar workflows : <flow_id> : <id> : convergingGateway : <id_1> <id_2> ... <id_n> "},{"title":"Workflow generation","baseurl":"","url":"/documentation/tosca_ref/tosca_concepts_workflows_default.html","date":null,"categories":[],"body":"TOSCA containers uses the default normative types to automatically generate a default workflow. This ease the definition of TOSCA topologies as in most of situations entities are extending from tosca.nodes.Root and tosca.relationships.Root . This section details how the default workflow is generated. "},{"title":"Normative Lifecycle","baseurl":"","url":"/documentation/tosca_ref/tosca_normative_lifecycle.html","date":null,"categories":[],"body":"TOSCA normative lifecycle is automatically generated by the TOSCA container based on the normative node and relationship types. Note that the TOSCA specification on lifecycle is still being written so this may be subject to changes before v1 release. Lifecycle is based on the normative node interface (tosca.interfaces.node.lifecycle.Standard) and relationship interface (tosca.interfaces.relationship.Configure). Node Lifecycle generation wait for all node that is a target of a DependsOn relationship to reach the started state (current node being source of the relationship). call the node’s create operation call the relationships pre_configure_source (if the node is the relationship source) or pre_configure_target (if the node is the relationship target) call the node’s configure operation call the relationships post_configure_source (if the node is the relationship source) or post_configure_target (if the node is the relationship target) call the node’s start operation call the relationships add_target (on the nodes sources) and add_source (on the nodes targets) operations. "},{"title":"Create your own components","baseurl":"","url":"/documentation/getting_started/tutorials.html","date":null,"categories":[],"body":" This documentation section is not complete. We recommend you to start with the lamp stack tutorials that have been upgraded more recently. Components Design of a component (Tomcat server) Implementation of a component Topologies Designing a topology in ALIEN Application Creation of an application and running it on a cloud using cloudify PaaS "},{"title":"Component design","baseurl":"","url":"/documentation/getting_started/tutorials_component_design.html","date":null,"categories":[],"body":"Target: Middleware experts, architects, operations teams. Goal: Explain how to start with component design. In this tutorial, the component we will focus on is Tomcat Application Server. Define the node type A component in ALIEN is a tosca node type. Information on TOSCA and the grammar can be found on OASIS TC pages and in ALIEN documentation in the components section. This tutorial doesn’t focus on the grammar but on the methodology to define components. The first step to define the component is to define it’s id. In our case, we will define a ‘fastconnect.nodes.Tomcat’ node. This component will be abstract as we don’t plan to include an implementation for now (another member of the team may provide an implementation). More, while an implementation may not be compliant with any Operating System (Linux shell scripts that won’t run on windows) or PaaS (Cloudify specific scripts) etc. The abstract type allows to define an agnostic view of the middleware. A same node may have different implementations, for example a Tomcat Node may have an implementation based on puppet and another based on chef, or even pure shell script. Definition of abstract types is also a good way also to provide separation of concern and to let an Architect define a middleware and let the implementation to the experts. Second step when defining a node is to find from which parent type it should extends, it can be an existing type already uploaded in ALIEN or one of TOSCA normative type . There is multiple reasons to extends from the normative types (or another type that itself extends from a normative type): Workflow automatic generation is based on the fact that the node uses the default lifecycle interfaces that are defined on the normative types. Using normative types is also a good way to leverage ALIEN 4 Cloud facet search (for example I will be able to filter on all ApplicationServer nodes). Finally extending from normative types allows to bootstrap your node with some properties, capabilities and requirements. For example as our Tomcat extends from tosca.nodes.SoftwareComponents it will have a version property that should be specified a host requirement (as a software component must be installed on a compute node). the default feature requirement and relationship that are used to established depends on relationships (to impact the lifecycle generation). In the case of a Tomcat server the normative type that we should extends from is tosca.nodes.ApplicationServer . This node extends itself from tosca.nodes.SoftwareComponents . fastconnect.nodes.Tomcat : abstract : true derived_from : tosca.nodes.ApplicationServer documentation : Tomcat application server is an application server that supports deployment of java web applications (war). It is possible here to create another parent abstract type that supports any Java Application Server. This would allow for any Java Application Server to just extends from the node and leverage common properties, requirements and capabilties (Java requirement, War capability, Java arguments properties etc.). Extension is not mandatory as this will just allow to simplify the definition of multiple bean but will not impact the topology creation. In order to keep this tutorial simple we will just extend our Tomcat from the tosca.nodes.ApplicationServer node type. Properties The first property we want to define is the version of tomcat that this tomcat definition supports. Indeed all the tomcat versions doesn’t have the same capabilities, for example tomcat 7.x supports web-sockets while this is not supported in tomcat 5.x for example. Version property as stated earlier is already defined in SoftwareComponent, it is possible however to override it to add an additional constraint. In this example we want to describe a tomcat node for all versions 7 so we will redefine the version property (with the same version type) and add constraints . Second property that we want to add in this tutorial is the java options to use to startup the Tomcat server. This will allow users to specify the java memory requirements and garbage collection settings. Name Type Required Default Constraints version version true 7 Between 7 (inclusive) and 8 exclusive java_ops string false None None fastconnect.nodes.Tomcat : abstract : true derived_from : tosca.nodes.ApplicationServer documentation : Tomcat application server is an application server that supports deployment of java web applications (war). properties : version : type : version constraints : - greater_or_equal : 7 - less_than : 8 java_ops : type : string Tomcat node with the version between [7 and 8) Of course we could add more properties to the tomcat node in order to allow configuration of other server related properties. In this tutorial we will just use the properties mentioned above. Note that as ALIEN supports the versioning of the archives it is easy to add properties later in a next version of the component. Requirements Next important section to describe on the Tomcat type is the list of requirements. As Tomcat inherit from SoftwareComponent it has an inherited requirement over a Compute node (this requirement can be fulfilled in a topology by using an hosted_on relationship). The other requirement for a Tomcat node is to have a java installed. We will model this by adding a java requirement to the tomcat node. A requirements can express constraints on some of the target capability or node, properties. Here we reference a requirement on a Java Node and specify a constraint on the version of the java node. Name Type Lower bound Upper bound Constraints Notes host tosca.nodes.Compute 1 (default) 1 (default)   Inherited from tosca.nodes.SoftwareComponent java fastconnect.nodes.Java 1 (default) 1 (default) Greater or equal than 7   fastconnect.nodes.Tomcat : abstract : true derived_from : tosca.nodes.ApplicationServer documentation : Tomcat application server is an application server that supports deployment of java web applications (war). properties : version : type : version constraints : - greater_or_equal : 7 - less_than : 8 java_ops : type : string requirements : java : type : fastconnect.nodes.Java constraints : version : { greater_or_equal : 1.7 } Tomcat node inherit from the requirement on a hosting compute node that is defined by the SoftwareComponent TOSCA normative node. Here we define an abstract Tomcat node that doesn’t have any specific requirement for the compute node (os type etc.) so we don’t have to override the parent requirement. Of course it is possible to override a parent requirement to specify more advanced constraints. Capabilities Tomcat has multiple capabilities and the two main capabilities that we want to define in this tutorial are the ability to hort some War node(s) on top of Tomcat as well as it’s http endpoint. Name Type Lower bound Upper bound http tosca.capabilities.Endpoint 0 (default) unbounded (default) war_host fastconnect.nodes.War 0 (default) unbounded (default) In case of the http capability we want to define the port of the tosca.capabilties.Endpoint to be actually the one define in the fastconnect.nodes.Tomcat : abstract : true derived_from : tosca.nodes.ApplicationServer documentation : Tomcat application server is an application server that supports deployment of java web applications (war). properties : version : type : version constraints : - greater_or_equal : 7 - less_than : 8 java_ops : type : string requirements : java : type : fastconnect.nodes.Java constraints : version : { greater_or_equal : 1.7 } capabilties : http : type : tosca.capabilities.Endpoint properties : port : 8080 war_host : type : fastconnect.capabilities.War Conclusion Following the tutorial you should be able to define your own types to be added in ALIEN repository. TOSCA’s requirement and capabilties mechanisms as well as constraint validations allows users to leverage your types so they can easily build topologies and minimize errors in configurations. The next step is to actually implement the type in order to have a type that can indeed be instantiated in a topology. "},{"title":"Component implementation","baseurl":"","url":"/documentation/getting_started/tutorials_component_implementation.html","date":null,"categories":[],"body":"Target: Middleware experts, operations teams. Goal: Explain how to implement a type. This tutorial follows the component design tutorial and we will describe how to implement the component designed in the previous tutorial. In this tutorial we also covers how the component archive can be added and tested through ALIEN. Pre-requisite: A git repository will hold the source code for the component archive. We will also use a Jenkins CI instance in order to demonstrate how we can continuously test our archives and develop components following quality best-practices. Prepare the archive Elements in TOSCA and ALIEN are defined in definitions files that can be packed in a Cloud Service Archive (CSAR). The first task therefore is to prepare the directory structure of our Cloud Service Archive. Then we create a tomcat-definition.yml file that will contain the actual tomcat node type definition. Before starting to fill-in the file we will first create the ALIEN-META.yaml file that must be in the TOSCA-Metadata folder of our archive directory structure. This file defines the archive name and version as well as the location of the definitions files that the archive contains. This is the entry point of the archive. The content of the file is the following: # Define the current archive id and version. name : \"fastconnect-tomcat-types\" version : \"1.0\" license : \"Apache v2.0\" created_by : \"FastConnect\" # List of definitions file in the archive. definitions : - /Definitions/tomcat-definition.yml Now that we have a cloud service archive with a definition file, we can edit it to define TOSCA elements. In our case we will focus on creating types. When creating type it is important to correctly defines the meta-informations of the type, and to try to reuse existing nodes, capabilities and requirements. "},{"title":"User management","baseurl":"","url":"/admin_guide/user_management.html","date":null,"categories":[],"body":"This section details Alien 4 Cloud’s ROLES and permissions by role. General Alien 4 Cloud roles This role list describes basic roles you can grant to a user. From his/her roles Alien 4 Cloud will display and allow some operations. For example, the navigation bar on top is configured regarding the user roles : Role Description ADMIN Manages users, plugins, configure clouds + all other roles. APPLICATIONS_MANAGER Create new application(s). ARCHITECT Create and edit topology template(s). COMPONENTS_BROWSER Can list components and see details for any of them COMPONENTS_MANAGER COMPONENTS_BROWSER rights + upload a CSAR archive to add components A user with no roles can log-in and view the resources for which he has been granted. For example a user with no roles but being listed as user in an application, can look at this application and do any operations he is authorized to perform for the application. Application’s roles This role list defines actions allowed by role on a given application : Role Description APPLICATION_MANAGER Almost all operations on his proper application. By default an application manager will also have deploy / undeploy right APPLICATION_USER Basic access like read (see details), search and get application’s status APPLICATION_DEVOPS APPLICATION_USER rights + topology handling DEPLOYMENT_MANAGER Mainly deploy / undeploy an application and basic access to a topology Application’s rights grid ( A )   APPLICATION_MANAGER APPLICATION_USER APPLICATION_DEVOPS DEPLOYMENT_MANAGER create         read X X X X search X X X X delete X       updateImage X       upsertTag X       deleteTag X       deploy       X undeploy       X getDeploymentStatus X X X X addApplicationUserRole X       removeApplicationUserRole X       Topologies’s rights grid ( T )   APPLICATION_MANAGER APPLICATION_USER APPLICATION_DEVOPS DEPLOYMENT_MANAGER create X       get X   X X addNodeTemplate X   X   updateNodeTemplateName X   X   addRelationshipTemplate X   X   deleteNodeTemplate X   X   updatePropertyValue X   X   isDeployable X     X Operations list A. Application’s operations create : Create a new application in the system read : Get an application based from its id search : Search for applications delete : Delete an application from its id updateImage : Application’s image update upsertTag : Update/Create a tag for the application deleteTag : Delete a tag for the application deploy : Deploys the application on the configured PaaS undeploy : Un-Deploys the application on the configured PaaS. getDeploymentStatus : Get the current status of the application on the PaaS addApplicationUserRole : Add a role to a user on a specific application removeApplicationUserRole : Remove a role to a user on a specific application T. Topologies’s operations create : Create a new empty topology get : Retrieve a topology from its id addNodeTemplate : Add a new node template in a topology updateNodeTemplateName : Change the name of a node template in a topology addRelationshipTemplate : Add a relationship to a node template deleteNodeTemplate : Delete a node tempalte from a topology updatePropertyValue : Update properties values isDeployable : Check if a topology is deployable or not "}]}